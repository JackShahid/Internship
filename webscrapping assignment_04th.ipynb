{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Scrape the details of most viewed videos on YouTube from Wikipedia:Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos/You need to find following details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = (\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos/\")\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = driver.find_element_by_xpath(\"//span[@class = 'plainlinks']\")\n",
    "link.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "link2 = driver.find_element_by_xpath(\"//div[@class ='mw-search-result-heading']\")\n",
    "link2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"9a27ad7c908f83e1e80143162a4a71ea\", element=\"e02dfcef-6d11-4d37-985a-0556bd349860\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"9a27ad7c908f83e1e80143162a4a71ea\", element=\"8aed39dd-d6d8-4a78-aae0-7554229e2303\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"9a27ad7c908f83e1e80143162a4a71ea\", element=\"24a4a197-0e3f-4d28-ae1e-f4d1c99a66e5\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"9a27ad7c908f83e1e80143162a4a71ea\", element=\"4a881ec0-8e92-4d3f-9958-0d551f6447be\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"9a27ad7c908f83e1e80143162a4a71ea\", element=\"084d85d0-34ba-4f4b-b576-2689816acd09\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"9a27ad7c908f83e1e80143162a4a71ea\", element=\"b17ea584-6a04-4032-866b-a45257c1d318\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"9a27ad7c908f83e1e80143162a4a71ea\", element=\"362ea17a-507e-40e7-a187-f7601e5769e9\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"9a27ad7c908f83e1e80143162a4a71ea\", element=\"78a9534a-3b0b-4102-ba40-0c8a0dc8aae7\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"9a27ad7c908f83e1e80143162a4a71ea\", element=\"4f87eb33-cc1a-47d5-949c-469881b925b2\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"9a27ad7c908f83e1e80143162a4a71ea\", element=\"5f6cc662-7efb-43f2-9865-b4a1b9055889\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"9a27ad7c908f83e1e80143162a4a71ea\", element=\"e38e5eb3-9058-47a1-adc9-e742ffdcca36\")>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank = driver.find_elements_by_xpath(\"//th[@title ='Sort ascending']\")\n",
    "rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['No.',\n",
       " 'Video name',\n",
       " 'Uploader',\n",
       " 'Views (billions)',\n",
       " 'Upload date',\n",
       " 'Video name',\n",
       " 'Uploader',\n",
       " 'Views*',\n",
       " 'Upload date',\n",
       " 'Date achieved',\n",
       " 'Days held']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rank =[]\n",
    "for i in rank:\n",
    "    Rank.append(i.text)\n",
    "Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['music videos',\n",
       " 'Baby Shark Dance',\n",
       " 'Baby Shark Dance',\n",
       " 'Johny Johny Yes Papa',\n",
       " 'Baby Shark Dance',\n",
       " 'Johny Johny Yes Papa',\n",
       " 'Cocomelon â€“ Nursery Rhymes',\n",
       " 'Cocomelon â€“ Nursery Rhymes',\n",
       " 'Cocomelon â€“ Nursery Rhymes',\n",
       " 'The Gummy Bear Song',\n",
       " 'Fueled By Ramen',\n",
       " 'The Gummy Bear Song',\n",
       " 'Osito Gominola â€“ Full Spanish Version â€“ The Gummy Bear Song',\n",
       " 'Baby Shark Dance',\n",
       " 'Johny Johny Yes Papa',\n",
       " 'Closer',\n",
       " 'Cocomelon â€“ Nursery Rhymes',\n",
       " 'Cocomelon â€“ Nursery Rhymes',\n",
       " 'Baby Shark Dance',\n",
       " 'List of most-viewed online trailers in the first 24 hours',\n",
       " 'regional restrictions',\n",
       " 'regional restrictions',\n",
       " 'Wired',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = driver.find_elements_by_xpath(\"//a[@class ='mw-redirect']\")\n",
    "Name =[]\n",
    "for i in name:\n",
    "    Name.append(i.text)\n",
    "Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pinkfong',\n",
       " \"Pinkfong Baby Shark - Kids' Songs & Stories\",\n",
       " 'Pinkfong',\n",
       " \"Pinkfong Baby Shark - Kids' Songs & Stories\"]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist = driver.find_elements_by_xpath(\"//a[@title = 'Pinkfong']\")\n",
    "Artist = []\n",
    "for i in artist:\n",
    "    Artist.append(i.text)\n",
    "Artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['June 17, 2016',\n",
       " 'January 12, 2017',\n",
       " 'October 8, 2016',\n",
       " 'January 30, 2017',\n",
       " 'April 6, 2015',\n",
       " 'May 2, 2018',\n",
       " 'February 27, 2018',\n",
       " 'January 31, 2012',\n",
       " 'November 19, 2014',\n",
       " 'March 6, 2014',\n",
       " 'July 15, 2012',\n",
       " 'April 5, 2018',\n",
       " 'January 14, 2015',\n",
       " 'October 22, 2015',\n",
       " 'September 5, 2013',\n",
       " 'May 31, 2013',\n",
       " 'October 7, 2014',\n",
       " 'May 24, 2018',\n",
       " 'February 20, 2014',\n",
       " 'December 3, 2015',\n",
       " 'May 31, 2018',\n",
       " 'March 22, 2015',\n",
       " 'April 11, 2014',\n",
       " 'August 18, 2014',\n",
       " 'July 25, 2012',\n",
       " 'June 16, 2009',\n",
       " 'June 29, 2017',\n",
       " 'November 9, 2017',\n",
       " 'June 4, 2010',\n",
       " 'October 22, 2015',\n",
       " '7,037,500,000',\n",
       " 'June 17, 2016',\n",
       " 'November 2, 2020',\n",
       " '2,993,700,000',\n",
       " 'January 12, 2017',\n",
       " 'August 4, 2017',\n",
       " '2,894,000,000',\n",
       " 'April 6, 2015',\n",
       " 'July 10, 2017',\n",
       " '803,700,000',\n",
       " 'July 15, 2012',\n",
       " 'November 24, 2012',\n",
       " '245,400,000',\n",
       " 'February 19, 2010',\n",
       " 'July 16, 2010',\n",
       " '178,400,000',\n",
       " 'November 24, 2009',\n",
       " 'April 14, 2010',\n",
       " '128,900,000',\n",
       " 'May 22, 2007',\n",
       " 'October 25, 2009',\n",
       " '118,900,000',\n",
       " 'April 6, 2006',\n",
       " 'May 2, 2009',\n",
       " '92,600,000',\n",
       " 'February 27, 2007',\n",
       " 'July 17, 2008',\n",
       " '78,400,000',\n",
       " 'April 6, 2006',\n",
       " 'March 15, 2008',\n",
       " '76,600,000',\n",
       " 'April 9, 2007',\n",
       " 'March 1, 2008',\n",
       " '10,600,000',\n",
       " 'April 6, 2006',\n",
       " 'May 19, 2006',\n",
       " '4,300,000',\n",
       " 'November 28, 2005',\n",
       " 'March 12, 2006',\n",
       " '2,700,000',\n",
       " 'January 31, 2006',\n",
       " 'February 18, 2006',\n",
       " '3,400,000',\n",
       " 'December 1, 2005',\n",
       " 'January 21, 2006',\n",
       " '2,300,000',\n",
       " 'December 18, 2005',\n",
       " 'January 9, 2006',\n",
       " '255,000',\n",
       " 'October 21, 2005',\n",
       " 'October 31, 2005',\n",
       " '247,000',\n",
       " 'October 5, 2005',\n",
       " 'October 29, 2005',\n",
       " '1',\n",
       " 'April 23, 2005',\n",
       " 'April 23, 2005']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date = driver.find_elements_by_xpath(\"//td[@align = 'right']\")\n",
    "Date =[]\n",
    "for i in date:\n",
    "    Date.append(i.text)\n",
    "Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.',\n",
       " '9.46',\n",
       " '[B]',\n",
       " '2.',\n",
       " '7.57',\n",
       " '[C]',\n",
       " '3.',\n",
       " '5.78',\n",
       " '[D]',\n",
       " '4.',\n",
       " '5.48',\n",
       " '[E]',\n",
       " '5.',\n",
       " '5.29',\n",
       " '[F]',\n",
       " '6.',\n",
       " '4.55',\n",
       " '[G]',\n",
       " '7.',\n",
       " '4.52',\n",
       " '[H]',\n",
       " '8.',\n",
       " '4.46',\n",
       " '[I]',\n",
       " '9.',\n",
       " '4.32',\n",
       " '[J]',\n",
       " '10.',\n",
       " '4.22',\n",
       " '11.',\n",
       " '4.21',\n",
       " '[K]',\n",
       " '12.',\n",
       " '3.63',\n",
       " '13.',\n",
       " '3.57',\n",
       " '14.',\n",
       " '3.47',\n",
       " '15.',\n",
       " '3.45',\n",
       " '16.',\n",
       " '3.41',\n",
       " '17.',\n",
       " '3.34',\n",
       " '18.',\n",
       " '3.29',\n",
       " '19.',\n",
       " '3.16',\n",
       " '20.',\n",
       " '3.16',\n",
       " '21.',\n",
       " '3.14',\n",
       " '22.',\n",
       " '3.11',\n",
       " '23.',\n",
       " '3.11',\n",
       " '24.',\n",
       " '3.10',\n",
       " '25.',\n",
       " '3.09',\n",
       " '26.',\n",
       " '3.04',\n",
       " '27.',\n",
       " '2.99',\n",
       " '28.',\n",
       " '2.98',\n",
       " '29.',\n",
       " '2.96',\n",
       " '30.',\n",
       " '2.89',\n",
       " '',\n",
       " '',\n",
       " '[57]',\n",
       " '[L]',\n",
       " '[29]',\n",
       " '[37]',\n",
       " '[M]',\n",
       " '[59]',\n",
       " '[N]',\n",
       " '93',\n",
       " '[63]',\n",
       " '[O]',\n",
       " '171',\n",
       " '[67]',\n",
       " '176',\n",
       " '[69]',\n",
       " '289',\n",
       " '[72]',\n",
       " '124',\n",
       " '[73]',\n",
       " '14',\n",
       " '[75]',\n",
       " '[P]',\n",
       " '[78]',\n",
       " '[Q]',\n",
       " '68',\n",
       " '[80]',\n",
       " '[R]',\n",
       " '22',\n",
       " '[85]',\n",
       " '28',\n",
       " '[87]',\n",
       " '[S]',\n",
       " '12',\n",
       " '[89]',\n",
       " '[91]',\n",
       " '[T]',\n",
       " '[94]',\n",
       " '[96]']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "views = driver.find_elements_by_xpath(\"//td[@align= 'center']\")\n",
    "View = []\n",
    "for i in views:\n",
    "    View.append(i.text)\n",
    "View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Date</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No.</td>\n",
       "      <td>music videos</td>\n",
       "      <td>Pinkfong</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>1.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Video name</td>\n",
       "      <td>Baby Shark Dance</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>9.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Uploader</td>\n",
       "      <td>Baby Shark Dance</td>\n",
       "      <td>Pinkfong</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>[B]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Views (billions)</td>\n",
       "      <td>Johny Johny Yes Papa</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>2.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Rank                  Name  \\\n",
       "0               No.          music videos   \n",
       "1        Video name      Baby Shark Dance   \n",
       "2          Uploader      Baby Shark Dance   \n",
       "3  Views (billions)  Johny Johny Yes Papa   \n",
       "\n",
       "                                        Artist              Date Views  \n",
       "0                                     Pinkfong     June 17, 2016    1.  \n",
       "1  Pinkfong Baby Shark - Kids' Songs & Stories  January 12, 2017  9.46  \n",
       "2                                     Pinkfong   October 8, 2016   [B]  \n",
       "3  Pinkfong Baby Shark - Kids' Songs & Stories  January 30, 2017    2.  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewed_video = pd.DataFrame({})\n",
    "viewed_video['Rank'] = Rank[:4]\n",
    "viewed_video['Name'] = Name[:4]\n",
    "viewed_video['Artist'] = Artist[:4]\n",
    "viewed_video['Date'] = Date[:4]\n",
    "viewed_video['Views'] = View[:4]\n",
    "\n",
    "viewed_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2. Scrape the details team Indiaâ€™s international fixtures from bcci.tv.Url = https://www.bcci.tv/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = (\"https://www.bcci.tv/\")\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "icon = driver.find_element_by_xpath(\"//div[@class ='navigation__drop-down drop-down drop-down--reveal-on-hover']\")\n",
    "icon.click()\n",
    "\n",
    "drop = driver.find_element_by_xpath(\"//div[@class ='drop-down__options']\")\n",
    "drop.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T20I',\n",
       " 'T20I',\n",
       " 'T20I',\n",
       " 'T20I',\n",
       " 'T20I',\n",
       " 'T20I',\n",
       " 'T20I',\n",
       " 'T20I',\n",
       " 'TEST',\n",
       " 'TEST',\n",
       " 'TEST',\n",
       " 'TEST',\n",
       " 'TEST',\n",
       " 'ODI',\n",
       " 'ODI',\n",
       " 'ODI',\n",
       " 'T20I',\n",
       " 'T20I',\n",
       " 'T20I',\n",
       " 'T20I']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match = driver.find_elements_by_xpath(\"//span[@class ='u-unskewed-text fixture__format']\")\n",
    "Match =[]\n",
    "for i in match:\n",
    "    Match.append(i.text)\n",
    "Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"2021 ICC MEN'S T20 WORLD CUP\",\n",
       " \"2021 ICC MEN'S T20 WORLD CUP\",\n",
       " \"2021 ICC MEN'S T20 WORLD CUP\",\n",
       " \"2021 ICC MEN'S T20 WORLD CUP\",\n",
       " \"2021 ICC MEN'S T20 WORLD CUP\",\n",
       " 'INDIA V NEW ZEALAND 2021',\n",
       " 'INDIA V NEW ZEALAND 2021',\n",
       " 'INDIA V NEW ZEALAND 2021',\n",
       " 'INDIA V NEW ZEALAND 2021',\n",
       " 'INDIA V NEW ZEALAND 2021',\n",
       " 'SOUTH AFRICA V INDIA 2021/2022',\n",
       " 'SOUTH AFRICA V INDIA 2021/2022',\n",
       " 'SOUTH AFRICA V INDIA 2021/2022',\n",
       " 'SOUTH AFRICA V INDIA 2021/2022',\n",
       " 'SOUTH AFRICA V INDIA 2021/2022',\n",
       " 'SOUTH AFRICA V INDIA 2021/2022',\n",
       " 'SOUTH AFRICA V INDIA 2021/2022',\n",
       " 'SOUTH AFRICA V INDIA 2021/2022',\n",
       " 'SOUTH AFRICA V INDIA 2021/2022',\n",
       " 'SOUTH AFRICA V INDIA 2021/2022']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series = driver.find_elements_by_xpath(\"//span[@class ='u-unskewed-text fixture__tournament-label u-truncated']\")\n",
    "Series =[]\n",
    "for i in series:\n",
    "    Series.append(i.text)\n",
    "Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Match 16\\nDubai International Stadium, Dubai',\n",
       " 'Match 28\\nDubai International Stadium, Dubai',\n",
       " 'Match 33\\nZayed Cricket Stadium, Abu Dhabi',\n",
       " 'Match 37\\nDubai International Stadium, Dubai',\n",
       " 'Match 42\\nDubai International Stadium, Dubai',\n",
       " '1st T20I\\nSawai Mansingh Stadium, Jaipur',\n",
       " '2nd T20I\\nJSCA International Stadium Complex, Ranchi',\n",
       " '3rd T20I\\nEden Gardens, Kolkata',\n",
       " '1st Test\\nGreen Park, Kanpur',\n",
       " '2nd Test\\nWankhede Stadium, Mumbai',\n",
       " '1st Test\\nNew Wanderers Stadium, Johannesburg',\n",
       " '2nd Test\\nSupersport Park, Centurion',\n",
       " '3rd Test\\nNew Wanderers Stadium, Johannesburg',\n",
       " '1st ODI\\nBoland Park, Paarl',\n",
       " '2nd ODI\\nNewlands, Cape Town',\n",
       " '3rd ODI\\nNewlands, Cape Town',\n",
       " '1st T20I\\nNewlands, Cape Town',\n",
       " '2nd T20I\\nNewlands, Cape Town',\n",
       " '3rd T20I\\nBoland Park, Paarl',\n",
       " '4th T20I\\nBoland Park, Paarl']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "place = driver.find_elements_by_xpath(\"//p[@class ='fixture__additional-info']\")\n",
    "Place =[]\n",
    "for i in place:\n",
    "    Place.append(i.text)\n",
    "Place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Place)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['24 OCTOBER 19:30 IST',\n",
       " '31 OCTOBER 19:30 IST',\n",
       " '03 NOVEMBER 19:30 IST',\n",
       " '05 NOVEMBER 19:30 IST',\n",
       " '08 NOVEMBER 19:30 IST',\n",
       " '17 NOVEMBER 19:00 IST',\n",
       " '19 NOVEMBER 19:00 IST',\n",
       " '21 NOVEMBER 19:00 IST',\n",
       " '25 NOVEMBER 09:30 IST',\n",
       " '03 DECEMBER 09:30 IST',\n",
       " '17 DECEMBER 13:30 IST',\n",
       " '26 DECEMBER 13:30 IST',\n",
       " '03 JANUARY 13:30 IST',\n",
       " '11 JANUARY 14:00 IST',\n",
       " '14 JANUARY 14:00 IST',\n",
       " '16 JANUARY 14:00 IST',\n",
       " '19 JANUARY 19:30 IST',\n",
       " '21 JANUARY 19:30 IST',\n",
       " '23 JANUARY 19:30 IST',\n",
       " '26 JANUARY 19:30 IST']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date = driver.find_elements_by_xpath(\"//div[@class ='fixture__full-date']\")\n",
    "Date = []\n",
    "for i in date:\n",
    "    Date.append(i.text.replace(\"\\n\", \" \"))\n",
    "Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['19:30 IST',\n",
       " '19:30 IST',\n",
       " '19:30 IST',\n",
       " '19:30 IST',\n",
       " '19:30 IST',\n",
       " '19:00 IST',\n",
       " '19:00 IST',\n",
       " '19:00 IST',\n",
       " '09:30 IST',\n",
       " '09:30 IST',\n",
       " '13:30 IST',\n",
       " '13:30 IST',\n",
       " '13:30 IST',\n",
       " '14:00 IST',\n",
       " '14:00 IST',\n",
       " '14:00 IST',\n",
       " '19:30 IST',\n",
       " '19:30 IST',\n",
       " '19:30 IST',\n",
       " '19:30 IST']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time = driver.find_elements_by_xpath(\"//span[@class ='fixture__time']\")\n",
    "Time =[]\n",
    "for i in time:\n",
    "    Time.append(i.text)\n",
    "Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match Title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T20I</td>\n",
       "      <td>2021 ICC MEN'S T20 WORLD CUP</td>\n",
       "      <td>Match 16\\nDubai International Stadium, Dubai</td>\n",
       "      <td>24 OCTOBER 19:30 IST</td>\n",
       "      <td>19:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T20I</td>\n",
       "      <td>2021 ICC MEN'S T20 WORLD CUP</td>\n",
       "      <td>Match 28\\nDubai International Stadium, Dubai</td>\n",
       "      <td>31 OCTOBER 19:30 IST</td>\n",
       "      <td>19:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T20I</td>\n",
       "      <td>2021 ICC MEN'S T20 WORLD CUP</td>\n",
       "      <td>Match 33\\nZayed Cricket Stadium, Abu Dhabi</td>\n",
       "      <td>03 NOVEMBER 19:30 IST</td>\n",
       "      <td>19:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T20I</td>\n",
       "      <td>2021 ICC MEN'S T20 WORLD CUP</td>\n",
       "      <td>Match 37\\nDubai International Stadium, Dubai</td>\n",
       "      <td>05 NOVEMBER 19:30 IST</td>\n",
       "      <td>19:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T20I</td>\n",
       "      <td>2021 ICC MEN'S T20 WORLD CUP</td>\n",
       "      <td>Match 42\\nDubai International Stadium, Dubai</td>\n",
       "      <td>08 NOVEMBER 19:30 IST</td>\n",
       "      <td>19:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>T20I</td>\n",
       "      <td>INDIA V NEW ZEALAND 2021</td>\n",
       "      <td>1st T20I\\nSawai Mansingh Stadium, Jaipur</td>\n",
       "      <td>17 NOVEMBER 19:00 IST</td>\n",
       "      <td>19:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>T20I</td>\n",
       "      <td>INDIA V NEW ZEALAND 2021</td>\n",
       "      <td>2nd T20I\\nJSCA International Stadium Complex, ...</td>\n",
       "      <td>19 NOVEMBER 19:00 IST</td>\n",
       "      <td>19:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>T20I</td>\n",
       "      <td>INDIA V NEW ZEALAND 2021</td>\n",
       "      <td>3rd T20I\\nEden Gardens, Kolkata</td>\n",
       "      <td>21 NOVEMBER 19:00 IST</td>\n",
       "      <td>19:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TEST</td>\n",
       "      <td>INDIA V NEW ZEALAND 2021</td>\n",
       "      <td>1st Test\\nGreen Park, Kanpur</td>\n",
       "      <td>25 NOVEMBER 09:30 IST</td>\n",
       "      <td>09:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TEST</td>\n",
       "      <td>INDIA V NEW ZEALAND 2021</td>\n",
       "      <td>2nd Test\\nWankhede Stadium, Mumbai</td>\n",
       "      <td>03 DECEMBER 09:30 IST</td>\n",
       "      <td>09:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TEST</td>\n",
       "      <td>SOUTH AFRICA V INDIA 2021/2022</td>\n",
       "      <td>1st Test\\nNew Wanderers Stadium, Johannesburg</td>\n",
       "      <td>17 DECEMBER 13:30 IST</td>\n",
       "      <td>13:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TEST</td>\n",
       "      <td>SOUTH AFRICA V INDIA 2021/2022</td>\n",
       "      <td>2nd Test\\nSupersport Park, Centurion</td>\n",
       "      <td>26 DECEMBER 13:30 IST</td>\n",
       "      <td>13:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TEST</td>\n",
       "      <td>SOUTH AFRICA V INDIA 2021/2022</td>\n",
       "      <td>3rd Test\\nNew Wanderers Stadium, Johannesburg</td>\n",
       "      <td>03 JANUARY 13:30 IST</td>\n",
       "      <td>13:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ODI</td>\n",
       "      <td>SOUTH AFRICA V INDIA 2021/2022</td>\n",
       "      <td>1st ODI\\nBoland Park, Paarl</td>\n",
       "      <td>11 JANUARY 14:00 IST</td>\n",
       "      <td>14:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ODI</td>\n",
       "      <td>SOUTH AFRICA V INDIA 2021/2022</td>\n",
       "      <td>2nd ODI\\nNewlands, Cape Town</td>\n",
       "      <td>14 JANUARY 14:00 IST</td>\n",
       "      <td>14:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ODI</td>\n",
       "      <td>SOUTH AFRICA V INDIA 2021/2022</td>\n",
       "      <td>3rd ODI\\nNewlands, Cape Town</td>\n",
       "      <td>16 JANUARY 14:00 IST</td>\n",
       "      <td>14:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>T20I</td>\n",
       "      <td>SOUTH AFRICA V INDIA 2021/2022</td>\n",
       "      <td>1st T20I\\nNewlands, Cape Town</td>\n",
       "      <td>19 JANUARY 19:30 IST</td>\n",
       "      <td>19:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>T20I</td>\n",
       "      <td>SOUTH AFRICA V INDIA 2021/2022</td>\n",
       "      <td>2nd T20I\\nNewlands, Cape Town</td>\n",
       "      <td>21 JANUARY 19:30 IST</td>\n",
       "      <td>19:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>T20I</td>\n",
       "      <td>SOUTH AFRICA V INDIA 2021/2022</td>\n",
       "      <td>3rd T20I\\nBoland Park, Paarl</td>\n",
       "      <td>23 JANUARY 19:30 IST</td>\n",
       "      <td>19:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>T20I</td>\n",
       "      <td>SOUTH AFRICA V INDIA 2021/2022</td>\n",
       "      <td>4th T20I\\nBoland Park, Paarl</td>\n",
       "      <td>26 JANUARY 19:30 IST</td>\n",
       "      <td>19:30 IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Match Title                          Series  \\\n",
       "0         T20I    2021 ICC MEN'S T20 WORLD CUP   \n",
       "1         T20I    2021 ICC MEN'S T20 WORLD CUP   \n",
       "2         T20I    2021 ICC MEN'S T20 WORLD CUP   \n",
       "3         T20I    2021 ICC MEN'S T20 WORLD CUP   \n",
       "4         T20I    2021 ICC MEN'S T20 WORLD CUP   \n",
       "5         T20I        INDIA V NEW ZEALAND 2021   \n",
       "6         T20I        INDIA V NEW ZEALAND 2021   \n",
       "7         T20I        INDIA V NEW ZEALAND 2021   \n",
       "8         TEST        INDIA V NEW ZEALAND 2021   \n",
       "9         TEST        INDIA V NEW ZEALAND 2021   \n",
       "10        TEST  SOUTH AFRICA V INDIA 2021/2022   \n",
       "11        TEST  SOUTH AFRICA V INDIA 2021/2022   \n",
       "12        TEST  SOUTH AFRICA V INDIA 2021/2022   \n",
       "13         ODI  SOUTH AFRICA V INDIA 2021/2022   \n",
       "14         ODI  SOUTH AFRICA V INDIA 2021/2022   \n",
       "15         ODI  SOUTH AFRICA V INDIA 2021/2022   \n",
       "16        T20I  SOUTH AFRICA V INDIA 2021/2022   \n",
       "17        T20I  SOUTH AFRICA V INDIA 2021/2022   \n",
       "18        T20I  SOUTH AFRICA V INDIA 2021/2022   \n",
       "19        T20I  SOUTH AFRICA V INDIA 2021/2022   \n",
       "\n",
       "                                                Place                   Date  \\\n",
       "0        Match 16\\nDubai International Stadium, Dubai   24 OCTOBER 19:30 IST   \n",
       "1        Match 28\\nDubai International Stadium, Dubai   31 OCTOBER 19:30 IST   \n",
       "2          Match 33\\nZayed Cricket Stadium, Abu Dhabi  03 NOVEMBER 19:30 IST   \n",
       "3        Match 37\\nDubai International Stadium, Dubai  05 NOVEMBER 19:30 IST   \n",
       "4        Match 42\\nDubai International Stadium, Dubai  08 NOVEMBER 19:30 IST   \n",
       "5            1st T20I\\nSawai Mansingh Stadium, Jaipur  17 NOVEMBER 19:00 IST   \n",
       "6   2nd T20I\\nJSCA International Stadium Complex, ...  19 NOVEMBER 19:00 IST   \n",
       "7                     3rd T20I\\nEden Gardens, Kolkata  21 NOVEMBER 19:00 IST   \n",
       "8                        1st Test\\nGreen Park, Kanpur  25 NOVEMBER 09:30 IST   \n",
       "9                  2nd Test\\nWankhede Stadium, Mumbai  03 DECEMBER 09:30 IST   \n",
       "10      1st Test\\nNew Wanderers Stadium, Johannesburg  17 DECEMBER 13:30 IST   \n",
       "11               2nd Test\\nSupersport Park, Centurion  26 DECEMBER 13:30 IST   \n",
       "12      3rd Test\\nNew Wanderers Stadium, Johannesburg   03 JANUARY 13:30 IST   \n",
       "13                        1st ODI\\nBoland Park, Paarl   11 JANUARY 14:00 IST   \n",
       "14                       2nd ODI\\nNewlands, Cape Town   14 JANUARY 14:00 IST   \n",
       "15                       3rd ODI\\nNewlands, Cape Town   16 JANUARY 14:00 IST   \n",
       "16                      1st T20I\\nNewlands, Cape Town   19 JANUARY 19:30 IST   \n",
       "17                      2nd T20I\\nNewlands, Cape Town   21 JANUARY 19:30 IST   \n",
       "18                       3rd T20I\\nBoland Park, Paarl   23 JANUARY 19:30 IST   \n",
       "19                       4th T20I\\nBoland Park, Paarl   26 JANUARY 19:30 IST   \n",
       "\n",
       "         Time  \n",
       "0   19:30 IST  \n",
       "1   19:30 IST  \n",
       "2   19:30 IST  \n",
       "3   19:30 IST  \n",
       "4   19:30 IST  \n",
       "5   19:00 IST  \n",
       "6   19:00 IST  \n",
       "7   19:00 IST  \n",
       "8   09:30 IST  \n",
       "9   09:30 IST  \n",
       "10  13:30 IST  \n",
       "11  13:30 IST  \n",
       "12  13:30 IST  \n",
       "13  14:00 IST  \n",
       "14  14:00 IST  \n",
       "15  14:00 IST  \n",
       "16  19:30 IST  \n",
       "17  19:30 IST  \n",
       "18  19:30 IST  \n",
       "19  19:30 IST  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcci = pd.DataFrame({})\n",
    "bcci['Match Title'] = Match\n",
    "bcci['Series'] = Series\n",
    "bcci['Place'] = Place\n",
    "bcci['Date'] = Date\n",
    "bcci['Time'] = Time\n",
    "\n",
    "bcci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Scrape the details of selenium exception from guru99.com.Url = https://www.guru99.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = (\"https://www.guru99.com/\")\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PractiTest',\n",
       " 'apilayer',\n",
       " 'Kobiton',\n",
       " 'Selenium',\n",
       " 'SAP',\n",
       " 'China Firewall Test',\n",
       " 'Python',\n",
       " 'Ethical Hacking',\n",
       " 'Java',\n",
       " 'Big Data',\n",
       " 'Linux',\n",
       " 'Informatica']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = driver.find_elements_by_xpath(\"//h4[@class= 'kt-blocks-info-box-title']\")\n",
    "Name = []\n",
    "for i in name:\n",
    "    Name.append(i.text)\n",
    "Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ðŸ‘‰ Lesson 1 What is TensorFlow? How it Works? â€” Introduction & Architecture\\nðŸ‘‰ Lesson 2 How to Download & Install TensorFLow â€” Jupyter | Windows/Mac\\nðŸ‘‰ Lesson 3 Jupyter Notebook Tutorial â€” How to Install & use Jupyter?\\nðŸ‘‰ Lesson 4 TensorFlow Basics â€” Tensor, Shape, Type, Sessions & Operators',\n",
       " 'ðŸ‘‰ Lesson 1 TensorBoard Tutorial â€” TensorFlow Graph Visualization [Example]\\nðŸ‘‰ Lesson 2 Python Pandas Tutorial â€” DataFrame, Date Range, Use of Pandas\\nðŸ‘‰ Lesson 3 Import CSV Data â€” Import CSV Data using Pandas.read_csv()\\nðŸ‘‰ Lesson 4 Linear Regression with TensorFlow â€” Learn with Example\\nðŸ‘‰ Lesson 5 Linear Regression with Facet & Interaction Term â€” Learn with Example\\nðŸ‘‰ Lesson 6 Binary Classification in TensorFlow â€” Linear Classifier Example\\nðŸ‘‰ Lesson 7 Gaussian Kernel in Machine Learning â€” Kernel Methods Examples\\nðŸ‘‰ Lesson 8 Artificial Neural Network (ANN) â€” TensorFlow Example Tutorial\\nðŸ‘‰ Lesson 9 TensorFlow CNN Image Classification â€” Learn with Steps & Examples\\nðŸ‘‰ Lesson 10 TensorFlow Autoencoder â€” Dataset with Deep Learning Example\\nðŸ‘‰ Lesson 11 RNN (Recurrent Neural Network) Tutorial â€” TensorFlow Example\\nðŸ‘‰ Lesson 12 PySpark Tutorial for Beginners â€” Learn with EXAMPLES\\nðŸ‘‰ Lesson 13 Scikit-Learn Tutorial â€” How to Install, Python Scikit-Learn Example\\nðŸ‘‰ Lesson 14 Python NumPy Tutorial â€” np.zeros, np.arange, vstack and hstack',\n",
       " 'ðŸ‘‰ Lesson 1 TensorFlow Books â€” 10 BEST TensorFlow Books\\nðŸ‘‰ Lesson 2 Tensorflow Tutorial PDF â€” Download Tensorflow Tutorial PDF for Beginners']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description =driver.find_elements_by_xpath(\"//table[@class = 'table']\")\n",
    "Description =[]\n",
    "for i in description:\n",
    "    Description.append(i.text)\n",
    "Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PractiTest</td>\n",
       "      <td>ðŸ‘‰ Lesson 1 What is TensorFlow? How it Works? â€”...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apilayer</td>\n",
       "      <td>ðŸ‘‰ Lesson 1 TensorBoard Tutorial â€” TensorFlow G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kobiton</td>\n",
       "      <td>ðŸ‘‰ Lesson 1 TensorFlow Books â€” 10 BEST TensorFl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Name                                        Description\n",
       "0  PractiTest  ðŸ‘‰ Lesson 1 What is TensorFlow? How it Works? â€”...\n",
       "1    apilayer  ðŸ‘‰ Lesson 1 TensorBoard Tutorial â€” TensorFlow G...\n",
       "2     Kobiton  ðŸ‘‰ Lesson 1 TensorFlow Books â€” 10 BEST TensorFl..."
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guru = pd.DataFrame({})\n",
    "\n",
    "guru['Name'] = Name[:3]\n",
    "guru['Description'] = Description[:3]\n",
    "guru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Scrape the details of State-wise GDP of India from statisticstime.com.Url = http://statisticstimes.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = (\"http://statisticstimes.com/\")\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "button = driver.find_element_by_xpath(\"//a[@class ='ec']\")\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " '10',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '17',\n",
       " '18',\n",
       " '19',\n",
       " '20',\n",
       " '21',\n",
       " '22',\n",
       " '23',\n",
       " '24',\n",
       " '25',\n",
       " '26',\n",
       " '27',\n",
       " '28',\n",
       " '29',\n",
       " '30',\n",
       " '31',\n",
       " '32',\n",
       " '33',\n",
       " '',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " '10',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '17',\n",
       " '18',\n",
       " '19',\n",
       " '20',\n",
       " '21',\n",
       " '22',\n",
       " '23',\n",
       " '24',\n",
       " '25',\n",
       " '26',\n",
       " '27',\n",
       " '28',\n",
       " '29',\n",
       " '30',\n",
       " '31',\n",
       " '32',\n",
       " '33',\n",
       " '']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank = driver.find_elements_by_xpath(\"//td[@class ='data1']\")\n",
    "Rank= []\n",
    "for i in rank:\n",
    "    Rank.append(i.text)\n",
    "Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mizoram',\n",
       " 'Tripura',\n",
       " 'Gujarat',\n",
       " 'Karnataka',\n",
       " 'Haryana',\n",
       " 'Delhi',\n",
       " 'Telangana',\n",
       " 'Sikkim',\n",
       " 'Uttarakhand',\n",
       " 'Chandigarh',\n",
       " 'Madhya Pradesh',\n",
       " 'Andhra Pradesh',\n",
       " 'Assam',\n",
       " 'Odisha',\n",
       " 'Himachal Pradesh',\n",
       " 'Tamil Nadu',\n",
       " 'Maharashtra',\n",
       " 'Rajasthan',\n",
       " 'Uttar Pradesh',\n",
       " 'Kerala',\n",
       " 'Bihar',\n",
       " 'Arunachal Pradesh',\n",
       " 'Jharkhand',\n",
       " 'Manipur',\n",
       " 'Punjab',\n",
       " 'Chhattisgarh',\n",
       " 'Jammu & Kashmir',\n",
       " 'Goa',\n",
       " 'Nagaland',\n",
       " 'West Bengal',\n",
       " 'Puducherry',\n",
       " 'Meghalaya',\n",
       " 'Andaman & Nicobar Islands',\n",
       " 'India',\n",
       " 'Mizoram',\n",
       " 'Gujarat',\n",
       " 'Tripura',\n",
       " 'Haryana',\n",
       " 'Karnataka',\n",
       " 'Uttarakhand',\n",
       " 'Telangana',\n",
       " 'Delhi',\n",
       " 'Himachal Pradesh',\n",
       " 'Sikkim',\n",
       " 'Madhya Pradesh',\n",
       " 'Chandigarh',\n",
       " 'Andhra Pradesh',\n",
       " 'Odisha',\n",
       " 'Assam',\n",
       " 'Tamil Nadu',\n",
       " 'Maharashtra',\n",
       " 'Kerala',\n",
       " 'Uttar Pradesh',\n",
       " 'Rajasthan',\n",
       " 'Jharkhand',\n",
       " 'Manipur',\n",
       " 'Bihar',\n",
       " 'Punjab',\n",
       " 'Arunachal Pradesh',\n",
       " 'Goa',\n",
       " 'Nagaland',\n",
       " 'Chhattisgarh',\n",
       " 'West Bengal',\n",
       " 'Jammu & Kashmir',\n",
       " 'Puducherry',\n",
       " 'Meghalaya',\n",
       " 'Andaman & Nicobar Islands',\n",
       " 'India']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = driver.find_elements_by_xpath(\"//td[@class ='name']\")\n",
    "State = []\n",
    "for i in state:\n",
    "    State.append(i.text)\n",
    "State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['14.07',\n",
       " '11.63',\n",
       " '18.91',\n",
       " '14.97',\n",
       " '17.56',\n",
       " '9.79',\n",
       " '11.69',\n",
       " '12.32',\n",
       " '14.02',\n",
       " '14.66',\n",
       " '-',\n",
       " '9.19',\n",
       " '-',\n",
       " '13.08',\n",
       " '13.61',\n",
       " '5.95',\n",
       " '6.67',\n",
       " '9.30',\n",
       " '11.68',\n",
       " '13.77',\n",
       " '7.75',\n",
       " '7.49',\n",
       " '13.27',\n",
       " '13.02',\n",
       " '13.79',\n",
       " '7.42',\n",
       " '7.71',\n",
       " '10.48',\n",
       " '12.82',\n",
       " '12.31',\n",
       " '8.23',\n",
       " '9.53',\n",
       " '12.61',\n",
       " '14.33',\n",
       " '13.30',\n",
       " '6.92',\n",
       " '5.94',\n",
       " '13.13',\n",
       " '10.60',\n",
       " '14.56',\n",
       " '-',\n",
       " '6.87',\n",
       " '-',\n",
       " '10.35',\n",
       " '11.44',\n",
       " '-',\n",
       " '7.39',\n",
       " '-',\n",
       " '14.22',\n",
       " '12.27',\n",
       " '7.62',\n",
       " '5.77',\n",
       " '11.99',\n",
       " '11.71',\n",
       " '14.48',\n",
       " '8.16',\n",
       " '4.45',\n",
       " '12.73',\n",
       " '8.80',\n",
       " '12.49',\n",
       " '-',\n",
       " '6.42',\n",
       " '-',\n",
       " '11.55',\n",
       " '11.99',\n",
       " '5.21',\n",
       " '4.23',\n",
       " '6.86',\n",
       " '10.64',\n",
       " '11.37',\n",
       " '5.56',\n",
       " '7.10',\n",
       " '7.56',\n",
       " '11.20',\n",
       " '11.31',\n",
       " '8.03',\n",
       " '7.95',\n",
       " '13.23',\n",
       " '11.27',\n",
       " '11.71',\n",
       " '-',\n",
       " '5.99',\n",
       " '-',\n",
       " '10.50',\n",
       " '10.87',\n",
       " '5.05',\n",
       " '6.97',\n",
       " '8.32',\n",
       " '12.86',\n",
       " '11.69',\n",
       " '3.81',\n",
       " '6.26',\n",
       " '6.50',\n",
       " '11.92',\n",
       " '11.86',\n",
       " '-',\n",
       " '7.46',\n",
       " '-',\n",
       " '11.41',\n",
       " '11.54',\n",
       " '10.47',\n",
       " '9.27',\n",
       " '15.36',\n",
       " '13.15',\n",
       " '11.55',\n",
       " '-',\n",
       " '4.59',\n",
       " '-',\n",
       " '9.68',\n",
       " '12.26',\n",
       " '6.69',\n",
       " '6.84',\n",
       " '10.56',\n",
       " '10.15',\n",
       " '10.40',\n",
       " '7.11',\n",
       " '2.93',\n",
       " '14.07',\n",
       " '8.07',\n",
       " '11.73',\n",
       " '5.33',\n",
       " '5.98',\n",
       " '9.19',\n",
       " '11.80',\n",
       " '10.22',\n",
       " '5.32',\n",
       " '7.06',\n",
       " '8.26',\n",
       " '10.95',\n",
       " '9.88',\n",
       " '-',\n",
       " '6.08',\n",
       " '-',\n",
       " '12.01',\n",
       " '10.45',\n",
       " '9.73',\n",
       " '9.75',\n",
       " '9.95',\n",
       " '5.51',\n",
       " '8.93',\n",
       " '-',\n",
       " '7.05',\n",
       " '-',\n",
       " '11.40',\n",
       " '12.27',\n",
       " '7.26',\n",
       " '6.41',\n",
       " '15.04',\n",
       " '11.82',\n",
       " '11.17',\n",
       " '9.04',\n",
       " '3.30',\n",
       " '11.09',\n",
       " '7.17',\n",
       " '10.88',\n",
       " '8.16',\n",
       " '9.38',\n",
       " '9.23',\n",
       " '13.46',\n",
       " '7.76',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '4.04',\n",
       " '6.53',\n",
       " '6.95',\n",
       " '7.75',\n",
       " '10.51',\n",
       " '11.72',\n",
       " '15.78',\n",
       " '11.56',\n",
       " '16.60',\n",
       " '14.85',\n",
       " '18.64',\n",
       " '-',\n",
       " '9.55',\n",
       " '-',\n",
       " '13.42',\n",
       " '13.90',\n",
       " '9.60',\n",
       " '11.27',\n",
       " '12.03',\n",
       " '13.49',\n",
       " '14.53',\n",
       " '7.77',\n",
       " '7.46',\n",
       " '13.47',\n",
       " '13.23',\n",
       " '13.73',\n",
       " '5.96',\n",
       " '6.32',\n",
       " '9.28',\n",
       " '11.45',\n",
       " '13.59',\n",
       " '-',\n",
       " '6.81',\n",
       " '-',\n",
       " '10.47',\n",
       " '11.77',\n",
       " '8.25',\n",
       " '9.65',\n",
       " '12.72',\n",
       " '14.43',\n",
       " '13.37',\n",
       " '7.27',\n",
       " '7.58',\n",
       " '10.66',\n",
       " '13.50',\n",
       " '12.21',\n",
       " '5.55',\n",
       " '7.45',\n",
       " '7.32',\n",
       " '11.68',\n",
       " '11.96',\n",
       " '6.81',\n",
       " '5.05',\n",
       " '12.93',\n",
       " '10.10',\n",
       " '14.61',\n",
       " '7.55',\n",
       " '5.59',\n",
       " '12.19',\n",
       " '12.01',\n",
       " '14.77',\n",
       " '-',\n",
       " '6.61',\n",
       " '-',\n",
       " '13.72',\n",
       " '12.10',\n",
       " '8.18',\n",
       " '4.51',\n",
       " '12.79',\n",
       " '8.86',\n",
       " '12.55',\n",
       " '5.07',\n",
       " '3.52',\n",
       " '6.94',\n",
       " '10.32',\n",
       " '11.28',\n",
       " '-',\n",
       " '6.11',\n",
       " '-',\n",
       " '11.45',\n",
       " '11.86',\n",
       " '8.14',\n",
       " '7.96',\n",
       " '13.23',\n",
       " '11.18',\n",
       " '11.73',\n",
       " '-',\n",
       " '5.77',\n",
       " '-',\n",
       " '10.53',\n",
       " '10.99',\n",
       " '-',\n",
       " '7.55',\n",
       " '-',\n",
       " '11.82',\n",
       " '11.61',\n",
       " '3.74',\n",
       " '5.99',\n",
       " '6.48',\n",
       " '11.87',\n",
       " '11.79',\n",
       " '5.04',\n",
       " '7.07',\n",
       " '8.37',\n",
       " '12.92',\n",
       " '11.47',\n",
       " '6.76',\n",
       " '6.71',\n",
       " '10.75',\n",
       " '9.98',\n",
       " '10.53',\n",
       " '7.67',\n",
       " '2.12',\n",
       " '15.10',\n",
       " '7.50',\n",
       " '12.09',\n",
       " '10.80',\n",
       " '9.01',\n",
       " '15.60',\n",
       " '12.91',\n",
       " '11.44',\n",
       " '5.41',\n",
       " '5.95',\n",
       " '9.53',\n",
       " '11.85',\n",
       " '10.23',\n",
       " '-',\n",
       " '4.80',\n",
       " '-',\n",
       " '9.38',\n",
       " '12.07',\n",
       " '9.51',\n",
       " '10.20',\n",
       " '9.26',\n",
       " '5.07',\n",
       " '9.09',\n",
       " '-',\n",
       " '8.18',\n",
       " '-',\n",
       " '12.84',\n",
       " '12.86',\n",
       " '5.18',\n",
       " '6.80',\n",
       " '8.07',\n",
       " '10.71',\n",
       " '9.47',\n",
       " '7.69',\n",
       " '6.20',\n",
       " '15.59',\n",
       " '11.76',\n",
       " '11.25',\n",
       " '-',\n",
       " '5.05',\n",
       " '-',\n",
       " '11.38',\n",
       " '9.99',\n",
       " '8.56',\n",
       " '2.76',\n",
       " '10.85',\n",
       " '6.72',\n",
       " '11.12',\n",
       " '8.19',\n",
       " '9.09',\n",
       " '11.13',\n",
       " '11.69',\n",
       " '7.36',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '3.60',\n",
       " '6.36',\n",
       " '6.74',\n",
       " '7.72',\n",
       " '10.33',\n",
       " '11.70']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsdp = driver.find_elements_by_xpath(\"//td[@class ='data']\")\n",
    "GSDP =[]\n",
    "for i in gsdp:\n",
    "    GSDP.append(i.text)\n",
    "GSDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "342"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(GSDP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['14.07',\n",
       " '11.63',\n",
       " '18.91',\n",
       " '14.97',\n",
       " '17.56',\n",
       " '9.79',\n",
       " '11.69',\n",
       " '12.32',\n",
       " '14.02',\n",
       " '14.66',\n",
       " '-',\n",
       " '9.19',\n",
       " '-',\n",
       " '13.08',\n",
       " '13.61',\n",
       " '5.95',\n",
       " '6.67',\n",
       " '9.30',\n",
       " '11.68',\n",
       " '13.77',\n",
       " '7.75',\n",
       " '7.49',\n",
       " '13.27',\n",
       " '13.02',\n",
       " '13.79',\n",
       " '7.42',\n",
       " '7.71',\n",
       " '10.48',\n",
       " '12.82',\n",
       " '12.31',\n",
       " '8.23',\n",
       " '9.53',\n",
       " '12.61',\n",
       " '14.33',\n",
       " '13.30',\n",
       " '6.92',\n",
       " '5.94',\n",
       " '13.13',\n",
       " '10.60',\n",
       " '14.56',\n",
       " '-',\n",
       " '6.87',\n",
       " '-',\n",
       " '10.35',\n",
       " '11.44',\n",
       " '-',\n",
       " '7.39',\n",
       " '-',\n",
       " '14.22',\n",
       " '12.27',\n",
       " '7.62',\n",
       " '5.77',\n",
       " '11.99',\n",
       " '11.71',\n",
       " '14.48',\n",
       " '8.16',\n",
       " '4.45',\n",
       " '12.73',\n",
       " '8.80',\n",
       " '12.49',\n",
       " '-',\n",
       " '6.42',\n",
       " '-',\n",
       " '11.55',\n",
       " '11.99',\n",
       " '5.21',\n",
       " '4.23',\n",
       " '6.86',\n",
       " '10.64',\n",
       " '11.37',\n",
       " '5.56',\n",
       " '7.10',\n",
       " '7.56',\n",
       " '11.20',\n",
       " '11.31',\n",
       " '8.03',\n",
       " '7.95',\n",
       " '13.23',\n",
       " '11.27',\n",
       " '11.71',\n",
       " '-',\n",
       " '5.99',\n",
       " '-',\n",
       " '10.50',\n",
       " '10.87',\n",
       " '5.05',\n",
       " '6.97',\n",
       " '8.32',\n",
       " '12.86',\n",
       " '11.69',\n",
       " '3.81',\n",
       " '6.26',\n",
       " '6.50',\n",
       " '11.92',\n",
       " '11.86',\n",
       " '-',\n",
       " '7.46',\n",
       " '-',\n",
       " '11.41',\n",
       " '11.54',\n",
       " '10.47',\n",
       " '9.27',\n",
       " '15.36',\n",
       " '13.15',\n",
       " '11.55',\n",
       " '-',\n",
       " '4.59',\n",
       " '-',\n",
       " '9.68',\n",
       " '12.26',\n",
       " '6.69',\n",
       " '6.84',\n",
       " '10.56',\n",
       " '10.15',\n",
       " '10.40',\n",
       " '7.11',\n",
       " '2.93',\n",
       " '14.07',\n",
       " '8.07',\n",
       " '11.73',\n",
       " '5.33',\n",
       " '5.98',\n",
       " '9.19',\n",
       " '11.80',\n",
       " '10.22',\n",
       " '5.32',\n",
       " '7.06',\n",
       " '8.26',\n",
       " '10.95',\n",
       " '9.88',\n",
       " '-',\n",
       " '6.08',\n",
       " '-',\n",
       " '12.01',\n",
       " '10.45',\n",
       " '9.73',\n",
       " '9.75',\n",
       " '9.95',\n",
       " '5.51',\n",
       " '8.93',\n",
       " '-',\n",
       " '7.05',\n",
       " '-',\n",
       " '11.40',\n",
       " '12.27',\n",
       " '7.26',\n",
       " '6.41',\n",
       " '15.04',\n",
       " '11.82',\n",
       " '11.17',\n",
       " '9.04',\n",
       " '3.30',\n",
       " '11.09',\n",
       " '7.17',\n",
       " '10.88',\n",
       " '8.16',\n",
       " '9.38',\n",
       " '9.23',\n",
       " '13.46',\n",
       " '7.76',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '4.04',\n",
       " '6.53',\n",
       " '6.95',\n",
       " '7.75',\n",
       " '10.51',\n",
       " '11.72',\n",
       " '15.78',\n",
       " '11.56',\n",
       " '16.60',\n",
       " '14.85',\n",
       " '18.64',\n",
       " '-',\n",
       " '9.55',\n",
       " '-',\n",
       " '13.42',\n",
       " '13.90',\n",
       " '9.60',\n",
       " '11.27',\n",
       " '12.03',\n",
       " '13.49',\n",
       " '14.53',\n",
       " '7.77',\n",
       " '7.46',\n",
       " '13.47',\n",
       " '13.23',\n",
       " '13.73',\n",
       " '5.96',\n",
       " '6.32',\n",
       " '9.28',\n",
       " '11.45',\n",
       " '13.59',\n",
       " '-',\n",
       " '6.81',\n",
       " '-',\n",
       " '10.47',\n",
       " '11.77',\n",
       " '8.25',\n",
       " '9.65',\n",
       " '12.72',\n",
       " '14.43',\n",
       " '13.37',\n",
       " '7.27',\n",
       " '7.58',\n",
       " '10.66',\n",
       " '13.50',\n",
       " '12.21',\n",
       " '5.55',\n",
       " '7.45',\n",
       " '7.32',\n",
       " '11.68',\n",
       " '11.96',\n",
       " '6.81',\n",
       " '5.05',\n",
       " '12.93',\n",
       " '10.10',\n",
       " '14.61',\n",
       " '7.55',\n",
       " '5.59',\n",
       " '12.19',\n",
       " '12.01',\n",
       " '14.77',\n",
       " '-',\n",
       " '6.61',\n",
       " '-',\n",
       " '13.72',\n",
       " '12.10',\n",
       " '8.18',\n",
       " '4.51',\n",
       " '12.79',\n",
       " '8.86',\n",
       " '12.55',\n",
       " '5.07',\n",
       " '3.52',\n",
       " '6.94',\n",
       " '10.32',\n",
       " '11.28',\n",
       " '-',\n",
       " '6.11',\n",
       " '-',\n",
       " '11.45',\n",
       " '11.86',\n",
       " '8.14',\n",
       " '7.96',\n",
       " '13.23',\n",
       " '11.18',\n",
       " '11.73',\n",
       " '-',\n",
       " '5.77',\n",
       " '-',\n",
       " '10.53',\n",
       " '10.99',\n",
       " '-',\n",
       " '7.55',\n",
       " '-',\n",
       " '11.82',\n",
       " '11.61',\n",
       " '3.74',\n",
       " '5.99',\n",
       " '6.48',\n",
       " '11.87',\n",
       " '11.79',\n",
       " '5.04',\n",
       " '7.07',\n",
       " '8.37',\n",
       " '12.92',\n",
       " '11.47',\n",
       " '6.76',\n",
       " '6.71',\n",
       " '10.75',\n",
       " '9.98',\n",
       " '10.53',\n",
       " '7.67',\n",
       " '2.12',\n",
       " '15.10',\n",
       " '7.50',\n",
       " '12.09',\n",
       " '10.80',\n",
       " '9.01',\n",
       " '15.60',\n",
       " '12.91',\n",
       " '11.44',\n",
       " '5.41',\n",
       " '5.95',\n",
       " '9.53',\n",
       " '11.85',\n",
       " '10.23',\n",
       " '-',\n",
       " '4.80',\n",
       " '-',\n",
       " '9.38',\n",
       " '12.07',\n",
       " '9.51',\n",
       " '10.20',\n",
       " '9.26',\n",
       " '5.07',\n",
       " '9.09',\n",
       " '-',\n",
       " '8.18',\n",
       " '-',\n",
       " '12.84',\n",
       " '12.86',\n",
       " '5.18',\n",
       " '6.80',\n",
       " '8.07',\n",
       " '10.71',\n",
       " '9.47',\n",
       " '7.69',\n",
       " '6.20',\n",
       " '15.59',\n",
       " '11.76',\n",
       " '11.25',\n",
       " '-',\n",
       " '5.05',\n",
       " '-',\n",
       " '11.38',\n",
       " '9.99',\n",
       " '8.56',\n",
       " '2.76',\n",
       " '10.85',\n",
       " '6.72',\n",
       " '11.12',\n",
       " '8.19',\n",
       " '9.09',\n",
       " '11.13',\n",
       " '11.69',\n",
       " '7.36',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '3.60',\n",
       " '6.36',\n",
       " '6.74',\n",
       " '7.72',\n",
       " '10.33',\n",
       " '11.70']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsdp18 = driver.find_elements_by_xpath(\"//td[@class ='data']\")\n",
    "GSDP18 = []\n",
    "for i in gsdp18:\n",
    "    GSDP18.append(i.text)\n",
    "GSDP18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "342"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(GSDP18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP</th>\n",
       "      <th>GSDP18-19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>14.07</td>\n",
       "      <td>14.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>11.63</td>\n",
       "      <td>11.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>18.91</td>\n",
       "      <td>18.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>14.97</td>\n",
       "      <td>14.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>17.56</td>\n",
       "      <td>17.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>30</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>11.55</td>\n",
       "      <td>11.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>31</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>11.99</td>\n",
       "      <td>11.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>32</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>5.21</td>\n",
       "      <td>5.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td></td>\n",
       "      <td>India</td>\n",
       "      <td>6.86</td>\n",
       "      <td>6.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State   GSDP GSDP18-19\n",
       "0     1                    Mizoram  14.07     14.07\n",
       "1     2                    Tripura  11.63     11.63\n",
       "2     3                    Gujarat  18.91     18.91\n",
       "3     4                  Karnataka  14.97     14.97\n",
       "4     5                    Haryana  17.56     17.56\n",
       "..  ...                        ...    ...       ...\n",
       "63   30            Jammu & Kashmir  11.55     11.55\n",
       "64   31                 Puducherry  11.99     11.99\n",
       "65   32                  Meghalaya   5.21      5.21\n",
       "66   33  Andaman & Nicobar Islands   4.23      4.23\n",
       "67                           India   6.86      6.86\n",
       "\n",
       "[68 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdp = pd.DataFrame({})\n",
    "gdp['Rank'] = Rank[:68]\n",
    "gdp['State'] = State[:68]\n",
    "gdp['GSDP'] = GSDP[:68]\n",
    "gdp['GSDP18-19'] = GSDP18[:68]\n",
    "gdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Scrape the details of trending repositories on Github.com.Url = https://github.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = (\"https://github.com/\")\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vitalets/github-trending-repos',\n",
       " 'mbadry1/Trending-Deep-Learning',\n",
       " 'laowch/GithubTrends',\n",
       " 'ophobe/trending',\n",
       " 'QasimWani/LeetHub',\n",
       " 'zhuowenli/githuber',\n",
       " 'andygrunwald/TrendingGithub',\n",
       " 'andygrunwald/go-trending',\n",
       " 'ecrmnn/trending-github',\n",
       " 'anitaa1990/Github-Trending-Repos']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = driver.find_elements_by_xpath(\"//div[@class ='f4 text-normal']\")\n",
    "Title =[]\n",
    "for i in title:\n",
    "    Title.append(i.text)\n",
    "Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Track GitHub trending repositories in your favorite programming language by native GitHub notifications!',\n",
       " 'Top 100 trending deep learning repositories sorted by the number of stars gained on a specific day.',\n",
       " \"It's a GitHub Trending repositories Viewer with Material Design.\",\n",
       " 'Dataset of trending repositories on GitHub',\n",
       " 'Automatically sync your leetcode solutions to your github account - top 5 trending GitHub repository',\n",
       " 'Display Github Trending repositories on Chrome New Tab Extensions',\n",
       " 'A twitter bot (@TrendingGithub) to tweet trending repositories and developers from GitHub',\n",
       " 'Go library for accessing trending repositories and developers at Github.',\n",
       " 'ðŸ“ˆ  Simple API for getting trending repositories on GitHub',\n",
       " 'An Android App that lists the most trending repositories from Github.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc = driver.find_elements_by_xpath(\"//p[@class ='mb-1']\")\n",
    "Desc = []\n",
    "for i in desc:\n",
    "    Desc.append(i.text)\n",
    "Desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2.2k',\n",
       " 'HTML',\n",
       " 'Updated on Sep 7, 2020',\n",
       " '558',\n",
       " 'Python',\n",
       " 'MIT license',\n",
       " 'Updated on Feb 2, 2020',\n",
       " '640',\n",
       " 'Java',\n",
       " 'Apache-2.0 license',\n",
       " 'Updated on Jun 10, 2019',\n",
       " '58',\n",
       " 'Updated on Aug 16, 2020',\n",
       " '759',\n",
       " 'JavaScript',\n",
       " 'MIT license',\n",
       " 'Updated on Sep 4',\n",
       " '440',\n",
       " 'JavaScript',\n",
       " 'MPL-2.0 license',\n",
       " 'Updated on Nov 17, 2020',\n",
       " '103',\n",
       " 'Go',\n",
       " 'MIT license',\n",
       " 'Updated on Jun 22',\n",
       " '116',\n",
       " 'Go',\n",
       " 'MIT license',\n",
       " 'Updated on Jul 12',\n",
       " '55',\n",
       " 'TypeScript',\n",
       " 'MIT license',\n",
       " 'Updated on Oct 29, 2020',\n",
       " '57',\n",
       " 'Java',\n",
       " 'Updated on Jan 15, 2019']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = driver.find_elements_by_xpath(\"//div[@class ='mr-3']\")\n",
    "Count =[]\n",
    "for i in count:\n",
    "    Count.append(i.text)\n",
    "Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HTML',\n",
       " 'Python',\n",
       " 'Java',\n",
       " 'JavaScript',\n",
       " 'JavaScript',\n",
       " 'Go',\n",
       " 'Go',\n",
       " 'TypeScript',\n",
       " 'Java']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language = driver.find_elements_by_xpath(\"//span[@itemprop = 'programmingLanguage']\")\n",
    "Language =[]\n",
    "for i in language:\n",
    "    Language.append(i.text)\n",
    "Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Count</th>\n",
       "      <th>Language_Used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vitalets/github-trending-repos</td>\n",
       "      <td>Track GitHub trending repositories in your fav...</td>\n",
       "      <td>2.2k</td>\n",
       "      <td>HTML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mbadry1/Trending-Deep-Learning</td>\n",
       "      <td>Top 100 trending deep learning repositories so...</td>\n",
       "      <td>HTML</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>laowch/GithubTrends</td>\n",
       "      <td>It's a GitHub Trending repositories Viewer wit...</td>\n",
       "      <td>Updated on Sep 7, 2020</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ophobe/trending</td>\n",
       "      <td>Dataset of trending repositories on GitHub</td>\n",
       "      <td>558</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>QasimWani/LeetHub</td>\n",
       "      <td>Automatically sync your leetcode solutions to ...</td>\n",
       "      <td>Python</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>zhuowenli/githuber</td>\n",
       "      <td>Display Github Trending repositories on Chrome...</td>\n",
       "      <td>MIT license</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>andygrunwald/TrendingGithub</td>\n",
       "      <td>A twitter bot (@TrendingGithub) to tweet trend...</td>\n",
       "      <td>Updated on Feb 2, 2020</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>andygrunwald/go-trending</td>\n",
       "      <td>Go library for accessing trending repositories...</td>\n",
       "      <td>640</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ecrmnn/trending-github</td>\n",
       "      <td>ðŸ“ˆ  Simple API for getting trending repositorie...</td>\n",
       "      <td>Java</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Title  \\\n",
       "0  vitalets/github-trending-repos   \n",
       "1  mbadry1/Trending-Deep-Learning   \n",
       "2             laowch/GithubTrends   \n",
       "3                 ophobe/trending   \n",
       "4               QasimWani/LeetHub   \n",
       "5              zhuowenli/githuber   \n",
       "6     andygrunwald/TrendingGithub   \n",
       "7        andygrunwald/go-trending   \n",
       "8          ecrmnn/trending-github   \n",
       "\n",
       "                                         Description                   Count  \\\n",
       "0  Track GitHub trending repositories in your fav...                    2.2k   \n",
       "1  Top 100 trending deep learning repositories so...                    HTML   \n",
       "2  It's a GitHub Trending repositories Viewer wit...  Updated on Sep 7, 2020   \n",
       "3         Dataset of trending repositories on GitHub                     558   \n",
       "4  Automatically sync your leetcode solutions to ...                  Python   \n",
       "5  Display Github Trending repositories on Chrome...             MIT license   \n",
       "6  A twitter bot (@TrendingGithub) to tweet trend...  Updated on Feb 2, 2020   \n",
       "7  Go library for accessing trending repositories...                     640   \n",
       "8  ðŸ“ˆ  Simple API for getting trending repositorie...                    Java   \n",
       "\n",
       "  Language_Used  \n",
       "0          HTML  \n",
       "1        Python  \n",
       "2          Java  \n",
       "3    JavaScript  \n",
       "4    JavaScript  \n",
       "5            Go  \n",
       "6            Go  \n",
       "7    TypeScript  \n",
       "8          Java  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "github = pd.DataFrame({})\n",
    "github['Title'] = Title[:9]\n",
    "github['Description'] = Desc[:9]\n",
    "github['Count'] = Count[:9]\n",
    "github['Language_Used'] = Language[:9]\n",
    "\n",
    "github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Scrape the details of top 100 songs on billboard.com.Url = https://www.billboard.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = (\"https://www.billboard.com/\")\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = driver.find_elements_by_xpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot = driver.find_element_by_xpath(\"//li[@class ='header__subnav__item']\")\n",
    "hot.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Stay',\n",
       " 'Industry Baby',\n",
       " 'Fancy Like',\n",
       " 'Way 2 Sexy',\n",
       " 'Bad Habits',\n",
       " 'Good 4 U',\n",
       " 'Kiss Me More',\n",
       " 'Levitating',\n",
       " 'Knife Talk',\n",
       " 'Essence',\n",
       " 'Shivers',\n",
       " 'My Universe',\n",
       " 'Need To Know',\n",
       " 'Save Your Tears',\n",
       " 'Heat Waves',\n",
       " \"Beggin'\",\n",
       " 'Montero (Call Me By Your Name)',\n",
       " 'You Right',\n",
       " \"If I Didn't Love You\",\n",
       " 'Girls Want Girls',\n",
       " 'Traitor',\n",
       " 'Take My Breath',\n",
       " 'Sharing Locations',\n",
       " 'Chasing After You',\n",
       " 'Pepas',\n",
       " 'Thats What I Want',\n",
       " 'Wockesha',\n",
       " 'Cold Beer Calling My Name',\n",
       " 'Happier Than Ever',\n",
       " 'Fair Trade',\n",
       " 'Deja Vu',\n",
       " 'Cold Heart (PNAU Remix)',\n",
       " \"Memory I Don't Mess With\",\n",
       " 'A-O-K',\n",
       " 'Love Nwantiti (Ah Ah Ah)',\n",
       " 'Intro (Hate On Me)',\n",
       " 'Leave The Door Open',\n",
       " 'Gyalis',\n",
       " 'Peaches',\n",
       " 'Leave Before You Love Me',\n",
       " 'Love Again',\n",
       " 'My Boy',\n",
       " 'Buy Dirt',\n",
       " 'Hurricane',\n",
       " 'I Was On A Boat That Day',\n",
       " 'Family Ties',\n",
       " 'Meet Me At Our Spot',\n",
       " 'Wild Side',\n",
       " 'Late At Night',\n",
       " 'Have Mercy',\n",
       " 'You Should Probably Leave',\n",
       " 'Whole Lotta Money',\n",
       " 'Cold As You',\n",
       " 'You Time',\n",
       " \"Drunk (And I Don't Wanna Go Home)\",\n",
       " 'Baddest',\n",
       " \"Thinking 'Bout You\",\n",
       " 'Butter',\n",
       " 'Too Easy',\n",
       " 'Hot',\n",
       " 'Your Heart',\n",
       " 'Woman',\n",
       " '2055',\n",
       " 'No Friends In The Industry',\n",
       " 'Champagne Poetry',\n",
       " 'Expensive Pain',\n",
       " 'Knowing You',\n",
       " 'Memory',\n",
       " 'On My Soul',\n",
       " 'Thot Shit',\n",
       " \"Drinkin' Beer. Talkin' God. Amen.\",\n",
       " 'Blue Note$ II',\n",
       " 'Volvi',\n",
       " 'Todo de Ti',\n",
       " 'Jugaste y Sufri',\n",
       " 'Outside (100 MPH)',\n",
       " 'Same Boat',\n",
       " 'Last One Standing',\n",
       " 'In The Bible',\n",
       " 'Chosen',\n",
       " 'Bad Morning',\n",
       " 'Yonaguni',\n",
       " 'The Feels',\n",
       " 'Summer Of Love',\n",
       " 'Get Into It (Yuh)',\n",
       " 'Nevada',\n",
       " 'Waves',\n",
       " 'Life Support',\n",
       " 'Me (FWM)',\n",
       " 'Love Train',\n",
       " 'Feelin Like Tunechi',\n",
       " 'One Mississippi',\n",
       " 'Ghost',\n",
       " 'Sand In My Boots',\n",
       " 'Ride For You',\n",
       " 'Esta Danada',\n",
       " 'Whiskey And Rain',\n",
       " 'TSU',\n",
       " 'Love All',\n",
       " 'No Where']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song = browser(\"//span[@class ='chart-element__information__song text--truncate color--primary']\")\n",
    "Song =[]\n",
    "for i in song:\n",
    "    Song.append(i.text)\n",
    "Song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Kid LAROI & Justin Bieber',\n",
       " 'Lil Nas X & Jack Harlow',\n",
       " 'Walker Hayes',\n",
       " 'Drake Featuring Future & Young Thug',\n",
       " 'Ed Sheeran',\n",
       " 'Olivia Rodrigo',\n",
       " 'Doja Cat Featuring SZA',\n",
       " 'Dua Lipa',\n",
       " 'Drake Featuring 21 Savage & Project Pat',\n",
       " 'Wizkid Featuring Justin Bieber & Tems',\n",
       " 'Ed Sheeran',\n",
       " 'Coldplay x BTS',\n",
       " 'Doja Cat',\n",
       " 'The Weeknd & Ariana Grande',\n",
       " 'Glass Animals',\n",
       " 'Maneskin',\n",
       " 'Lil Nas X',\n",
       " 'Doja Cat & The Weeknd',\n",
       " 'Jason Aldean & Carrie Underwood',\n",
       " 'Drake Featuring Lil Baby',\n",
       " 'Olivia Rodrigo',\n",
       " 'The Weeknd',\n",
       " 'Meek Mill Featuring Lil Baby & Lil Durk',\n",
       " 'Ryan Hurd With Maren Morris',\n",
       " 'Farruko',\n",
       " 'Lil Nas X',\n",
       " 'Moneybagg Yo',\n",
       " 'Jameson Rodgers Featuring Luke Combs',\n",
       " 'Billie Eilish',\n",
       " 'Drake Featuring Travis Scott',\n",
       " 'Olivia Rodrigo',\n",
       " 'Elton John & Dua Lipa',\n",
       " 'Lee Brice',\n",
       " 'Tai Verdes',\n",
       " 'CKay',\n",
       " 'Meek Mill',\n",
       " 'Silk Sonic (Bruno Mars & Anderson .Paak)',\n",
       " 'Capella Grey',\n",
       " 'Justin Bieber Featuring Daniel Caesar & Giveon',\n",
       " 'Marshmello X Jonas Brothers',\n",
       " 'Dua Lipa',\n",
       " 'Elvie Shane',\n",
       " 'Jordan Davis Featuring Luke Bryan',\n",
       " 'Kanye West',\n",
       " 'Old Dominion',\n",
       " 'Baby Keem & Kendrick Lamar',\n",
       " 'THE ANXIETY: WILLOW & Tyler Cole',\n",
       " 'Normani Featuring Cardi B',\n",
       " 'Roddy Ricch',\n",
       " 'Chloe',\n",
       " 'Chris Stapleton',\n",
       " 'BIA Featuring Nicki Minaj',\n",
       " 'Luke Combs',\n",
       " 'Scotty McCreery',\n",
       " 'Elle King & Miranda Lambert',\n",
       " 'Yung Bleu, Chris Brown & 2 Chainz',\n",
       " 'Dustin Lynch Featuring Lauren Alaina Or MacKenzie Porter',\n",
       " 'BTS',\n",
       " 'Gunna & Future',\n",
       " 'Meek Mill Featuring Moneybagg Yo',\n",
       " 'Joyner Lucas & J. Cole',\n",
       " 'Doja Cat',\n",
       " 'Sleepy Hallow',\n",
       " 'Drake',\n",
       " 'Drake',\n",
       " 'Meek Mill',\n",
       " 'Kenny Chesney',\n",
       " 'Kane Brown X blackbear',\n",
       " 'Meek Mill',\n",
       " 'Megan Thee Stallion',\n",
       " 'Chase Rice Featuring Florida Georgia Line',\n",
       " 'Meek Mill Featuring Lil Uzi Vert',\n",
       " 'Aventura x Bad Bunny',\n",
       " 'Rauw Alejandro',\n",
       " 'Eslabon Armado Featuring DannyLux',\n",
       " 'Meek Mill',\n",
       " 'Zac Brown Band',\n",
       " 'Skylar Grey, Polo G, Mozzy & Eminem',\n",
       " 'Drake Featuring Lil Durk & Giveon',\n",
       " 'Blxst & Tyga Featuring Ty Dolla $ign',\n",
       " 'YoungBoy Never Broke Again',\n",
       " 'Bad Bunny',\n",
       " 'TWICE',\n",
       " 'Shawn Mendes & Tainy',\n",
       " 'Doja Cat',\n",
       " 'YoungBoy Never Broke Again',\n",
       " 'Luke Bryan',\n",
       " 'YoungBoy Never Broke Again',\n",
       " 'Meek Mill Featuring A$AP Ferg',\n",
       " 'Meek Mill',\n",
       " 'Lil Wayne Featuring Rich The Kid',\n",
       " 'Kane Brown',\n",
       " 'Justin Bieber',\n",
       " 'Morgan Wallen',\n",
       " 'Meek Mill Featuring Kehlani',\n",
       " 'Ivan Cornejo',\n",
       " 'Michael Ray',\n",
       " 'Drake',\n",
       " 'Drake Featuring JAY-Z',\n",
       " 'YoungBoy Never Broke Again']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist = browser(\"//span[@class = 'chart-element__information__artist text--truncate color--secondary']\")\n",
    "Artist = []\n",
    "for i in artist:\n",
    "    Artist.append(i.text)\n",
    "Artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Artist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2',\n",
       " '3',\n",
       " '5',\n",
       " '4',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '10',\n",
       " '9',\n",
       " '11',\n",
       " '14',\n",
       " '1',\n",
       " '16',\n",
       " '12',\n",
       " '15',\n",
       " '19',\n",
       " '13',\n",
       " '18',\n",
       " '21',\n",
       " '17',\n",
       " '25',\n",
       " '22',\n",
       " '71',\n",
       " '27',\n",
       " '29',\n",
       " '24',\n",
       " '20',\n",
       " '26',\n",
       " '31',\n",
       " '23',\n",
       " '30',\n",
       " '46',\n",
       " '43',\n",
       " '35',\n",
       " '50',\n",
       " '-',\n",
       " '33',\n",
       " '64',\n",
       " '41',\n",
       " '39',\n",
       " '57',\n",
       " '66',\n",
       " '55',\n",
       " '34',\n",
       " '49',\n",
       " '42',\n",
       " '47',\n",
       " '51',\n",
       " '44',\n",
       " '56',\n",
       " '81',\n",
       " '52',\n",
       " '65',\n",
       " '63',\n",
       " '68',\n",
       " '77',\n",
       " '76',\n",
       " '36',\n",
       " '38',\n",
       " '-',\n",
       " '32',\n",
       " '75',\n",
       " '78',\n",
       " '60',\n",
       " '54',\n",
       " '-',\n",
       " '90',\n",
       " '79',\n",
       " '-',\n",
       " '73',\n",
       " '82',\n",
       " '-',\n",
       " '85',\n",
       " '86',\n",
       " '-',\n",
       " '-',\n",
       " '95',\n",
       " '-',\n",
       " '72',\n",
       " '98',\n",
       " '28',\n",
       " '89',\n",
       " '-',\n",
       " '93',\n",
       " '94',\n",
       " '58',\n",
       " '70',\n",
       " '48',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '-',\n",
       " '84',\n",
       " '87',\n",
       " '40']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank = browser(\"//div[@class ='chart-element__meta text--center color--secondary text--last']\")\n",
    "Rank = []\n",
    "for i in rank:\n",
    "    Rank.append(i.text)\n",
    "Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '2',\n",
       " '3',\n",
       " '1',\n",
       " '2',\n",
       " '1',\n",
       " '3',\n",
       " '2',\n",
       " '4',\n",
       " '10',\n",
       " '11',\n",
       " '1',\n",
       " '13',\n",
       " '1',\n",
       " '15',\n",
       " '16',\n",
       " '1',\n",
       " '11',\n",
       " '15',\n",
       " '2',\n",
       " '9',\n",
       " '6',\n",
       " '22',\n",
       " '24',\n",
       " '25',\n",
       " '10',\n",
       " '20',\n",
       " '26',\n",
       " '11',\n",
       " '3',\n",
       " '3',\n",
       " '32',\n",
       " '33',\n",
       " '34',\n",
       " '35',\n",
       " '36',\n",
       " '1',\n",
       " '38',\n",
       " '1',\n",
       " '19',\n",
       " '41',\n",
       " '42',\n",
       " '43',\n",
       " '6',\n",
       " '45',\n",
       " '18',\n",
       " '44',\n",
       " '14',\n",
       " '20',\n",
       " '28',\n",
       " '51',\n",
       " '16',\n",
       " '53',\n",
       " '50',\n",
       " '53',\n",
       " '56',\n",
       " '57',\n",
       " '1',\n",
       " '38',\n",
       " '60',\n",
       " '32',\n",
       " '62',\n",
       " '51',\n",
       " '11',\n",
       " '4',\n",
       " '66',\n",
       " '67',\n",
       " '50',\n",
       " '69',\n",
       " '16',\n",
       " '24',\n",
       " '72',\n",
       " '22',\n",
       " '32',\n",
       " '75',\n",
       " '76',\n",
       " '77',\n",
       " '78',\n",
       " '7',\n",
       " '80',\n",
       " '28',\n",
       " '10',\n",
       " '83',\n",
       " '48',\n",
       " '68',\n",
       " '58',\n",
       " '24',\n",
       " '48',\n",
       " '89',\n",
       " '90',\n",
       " '91',\n",
       " '73',\n",
       " '66',\n",
       " '32',\n",
       " '95',\n",
       " '96',\n",
       " '97',\n",
       " '9',\n",
       " '10',\n",
       " '40']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peak = browser(\"//div[@class ='chart-element__meta text--center color--secondary text--peak']\")\n",
    "Peak = []\n",
    "for i in peak:\n",
    "    Peak.append(i.text)\n",
    "Peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Peak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['13',\n",
       " '11',\n",
       " '16',\n",
       " '5',\n",
       " '15',\n",
       " '21',\n",
       " '26',\n",
       " '53',\n",
       " '5',\n",
       " '14',\n",
       " '4',\n",
       " '2',\n",
       " '17',\n",
       " '43',\n",
       " '38',\n",
       " '15',\n",
       " '28',\n",
       " '15',\n",
       " '11',\n",
       " '5',\n",
       " '20',\n",
       " '9',\n",
       " '6',\n",
       " '23',\n",
       " '11',\n",
       " '3',\n",
       " '24',\n",
       " '14',\n",
       " '10',\n",
       " '5',\n",
       " '27',\n",
       " '5',\n",
       " '11',\n",
       " '14',\n",
       " '3',\n",
       " '1',\n",
       " '31',\n",
       " '10',\n",
       " '29',\n",
       " '20',\n",
       " '12',\n",
       " '15',\n",
       " '9',\n",
       " '6',\n",
       " '14',\n",
       " '6',\n",
       " '4',\n",
       " '12',\n",
       " '18',\n",
       " '4',\n",
       " '14',\n",
       " '13',\n",
       " '10',\n",
       " '10',\n",
       " '24',\n",
       " '10',\n",
       " '8',\n",
       " '20',\n",
       " '2',\n",
       " '1',\n",
       " '2',\n",
       " '10',\n",
       " '12',\n",
       " '5',\n",
       " '5',\n",
       " '1',\n",
       " '8',\n",
       " '13',\n",
       " '1',\n",
       " '17',\n",
       " '19',\n",
       " '2',\n",
       " '10',\n",
       " '19',\n",
       " '1',\n",
       " '1',\n",
       " '3',\n",
       " '1',\n",
       " '5',\n",
       " '2',\n",
       " '2',\n",
       " '18',\n",
       " '1',\n",
       " '7',\n",
       " '9',\n",
       " '2',\n",
       " '16',\n",
       " '4',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '2',\n",
       " '2',\n",
       " '12',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '5',\n",
       " '5',\n",
       " '2']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charts = browser(\"//div[@class ='chart-element__meta text--center color--secondary text--week']\")\n",
    "Charts =[]\n",
    "for i in charts:\n",
    "    Charts.append(i.text)\n",
    "Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Charts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Peak</th>\n",
       "      <th>Charts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stay</td>\n",
       "      <td>The Kid LAROI &amp; Justin Bieber</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Industry Baby</td>\n",
       "      <td>Lil Nas X &amp; Jack Harlow</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fancy Like</td>\n",
       "      <td>Walker Hayes</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Way 2 Sexy</td>\n",
       "      <td>Drake Featuring Future &amp; Young Thug</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bad Habits</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Esta Danada</td>\n",
       "      <td>Ivan Cornejo</td>\n",
       "      <td>-</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Whiskey And Rain</td>\n",
       "      <td>Michael Ray</td>\n",
       "      <td>-</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>TSU</td>\n",
       "      <td>Drake</td>\n",
       "      <td>84</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Love All</td>\n",
       "      <td>Drake Featuring JAY-Z</td>\n",
       "      <td>87</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>No Where</td>\n",
       "      <td>YoungBoy Never Broke Again</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Song                               Artist Rank Peak Charts\n",
       "0               Stay        The Kid LAROI & Justin Bieber    2    1     13\n",
       "1      Industry Baby              Lil Nas X & Jack Harlow    3    2     11\n",
       "2         Fancy Like                         Walker Hayes    5    3     16\n",
       "3         Way 2 Sexy  Drake Featuring Future & Young Thug    4    1      5\n",
       "4         Bad Habits                           Ed Sheeran    6    2     15\n",
       "..               ...                                  ...  ...  ...    ...\n",
       "95       Esta Danada                         Ivan Cornejo    -   96      1\n",
       "96  Whiskey And Rain                          Michael Ray    -   97      1\n",
       "97               TSU                                Drake   84    9      5\n",
       "98          Love All                Drake Featuring JAY-Z   87   10      5\n",
       "99          No Where           YoungBoy Never Broke Again   40   40      2\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "billboard = pd.DataFrame({})\n",
    "billboard['Song'] = Song\n",
    "billboard['Artist'] = Artist\n",
    "billboard['Rank'] = Rank\n",
    "billboard['Peak'] = Peak\n",
    "billboard['Charts'] = Charts\n",
    "billboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Scrape the details of Data science recruiters from naukri.com.Url = https://www.naukri.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = (\"https://www.naukri.com/\")\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element_by_xpath(\"//input[@class ='sugInp']\")\n",
    "search.send_keys('Data Science')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "button = driver.find_element_by_xpath(\"//button[@class = 'btn']\")\n",
    "button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Inflexion Analytix Private Limited',\n",
       " 'Tiger Analytics India LLP',\n",
       " 'Data Trained Education',\n",
       " 'Tata Consultancy Services Ltd.',\n",
       " 'Info Edge',\n",
       " 'AUTOMOTIVE ROBOTICS (INDIA) PRIVATE LIMITED',\n",
       " 'Tredence Analytics Solutions Private Limited',\n",
       " 'Synergistic Compusoft Private Limited',\n",
       " 'Accenture Solutions Pvt Ltd',\n",
       " 'Accenture Solutions Pvt Ltd',\n",
       " 'Flipkart Internet Private Limited',\n",
       " 'Flipkart Internet Private Limited',\n",
       " 'RANDSTAD INDIA PVT LTD',\n",
       " 'Step Next Private Limited',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'Resilient Innovations Private Limited',\n",
       " 'Accenture Solutions Pvt Ltd',\n",
       " 'Accenture Solutions Pvt Ltd',\n",
       " 'Accenture Solutions Pvt Ltd',\n",
       " 'Accenture Solutions Pvt Ltd']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = browser(\"//a[@class = 'subTitle ellipsis fleft']\")\n",
    "Name =[]\n",
    "for i in name:\n",
    "    Name.append(i.text)\n",
    "Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Science / Business Analyst - Big Data Engineer',\n",
       " 'Senior Analyst - Data Science',\n",
       " 'Data Science (Using ML with Python) Intern - DataTrained',\n",
       " 'Tcs Hiring For Data Science Developer - PAN India',\n",
       " 'Naukri is hiring Content Specialist-Data Science/Technology/Management',\n",
       " 'Data Analysis/Data Science',\n",
       " 'Hiring Data Science professionals For Tredence!',\n",
       " 'Hiring Data Science/Machine Learning Trainer-Part-time/Full time',\n",
       " 'ACN - Applied Intelligence - CC - Data Science (IN) - 09',\n",
       " 'ACN - Applied Intelligence - CC - Data Science (IN) - 09',\n",
       " 'Software Development Engineer III - Data Sciences',\n",
       " 'Software Development Engineer II - Data Sciences',\n",
       " 'Business Intelligence Analyst with Data Science-Bangalore Location-C2H',\n",
       " 'Senior Data Analyst(Data Science) - 2 & PRO/Marketing Executives - 4',\n",
       " 'Data Science',\n",
       " 'Urgent Hiring | Data Science Engineer | BharatPe',\n",
       " 'ACN - Applied Intelligence - CC - Data Science',\n",
       " 'ACN - Applied Intelligence - CC - Data Science (IN) - 10',\n",
       " 'ACN - Applied Intelligence - CC - Data Science (IN) - 10',\n",
       " 'ACN - Applied Intelligence - CC - Data Science (IN) - 10']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "designation = browser(\"//a[@class = 'title fw500 ellipsis']\")\n",
    "Designation =[]\n",
    "for i in designation:\n",
    "    Designation.append(i.text)\n",
    "Designation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Designation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IT Skills\\nPython\\nData Science\\nMachine Learning\\nArtificial Intelligence\\nCloud\\nBig Data\\nBusiness Intelligence',\n",
       " 'verbal communication\\nwritten\\nR\\npython\\nIT Skills\\nData Science\\nMachine Learning\\nArtificial Intelligence',\n",
       " 'Data Science\\nR\\nTableau\\nMachine Learning\\nDeep Learning',\n",
       " 'Data Science\\nMachine Learning\\nPython\\nnltk\\nPower BI\\nstatistical modeling\\npandas\\nTableau',\n",
       " 'Data Science\\nTechnology Management\\nContent Creation\\nTechnology\\nSubject Matter Expertise\\nComputer Science\\nContent Writing\\nTechnical Writing',\n",
       " 'Power Bi\\nData Analysis\\nTableau\\nSQL Scripting\\nPython',\n",
       " 'Data Science\\nPython\\nSQL\\nNltk\\nNatural Language Processing\\nNeural Networks\\nMachine Learning',\n",
       " 'Data Science\\nTrainer\\nMachine Learning\\ncommunication\\nPython\\nNLP\\nJava\\nTableau',\n",
       " 'requirements gathering\\nanalytical\\nIT Skills\\nData Science\\nComputer science\\nVersion control\\nGIT\\nSAS',\n",
       " 'Computer science\\nVersion control\\nGIT\\nSAS\\nConsulting\\nMachine learning\\nApplication development\\nManager Quality Control',\n",
       " 'Supply chain\\nData analysis\\nLinux\\nCoding\\nMySQL\\nMachine learning\\nMentor\\nData structures',\n",
       " 'Supply chain\\nData analysis\\nSoftware design\\nSoftware Development Engineer II\\nCoding\\nMachine learning\\nData structures\\nDistribution system',\n",
       " 'Business Intelligence\\nDW/BI\\nHadoop\\nBig Data\\nSQL\\nData Science\\nPresto\\nHive',\n",
       " 'Data Science\\nMachine Learning\\nPython\\nIT Skills\\nArtificial Intelligence\\nProject Management\\nTableau\\nPower BI',\n",
       " 'IT Skills\\nPython\\nCloud\\nAWS\\nTableau\\nPower BI\\nAzure\\nArchitecture',\n",
       " 'Data Science',\n",
       " 'Computer science\\nAnalytical\\nConsulting\\nMachine learning\\nResourcing\\nApplication development\\nManager Quality Control\\nFMCG',\n",
       " 'IT Skills\\nPython\\nMachine Learning\\nCloud\\nAWS\\nTableau\\nPower BI\\nMatplotlib',\n",
       " 'IT Skills\\nPython\\nMachine Learning\\nCloud\\nAWS\\nTableau\\nPower BI\\nMatplotlib',\n",
       " 'analytical\\nComputer science\\nData analysis\\nVersion control\\nGIT\\nData modeling\\nCoding\\nConsulting']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skills  = browser(\"//ul[@class ='tags has-description']\")\n",
    "Skills =[]\n",
    "for i in skills:\n",
    "    Skills.append(i.text)\n",
    "Skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hyderabad/Secunderabad, Chennai',\n",
       " 'Kolkata, Hyderabad/Secunderabad, Pune, Ahmedabad, Chennai, Bangalore/Bengaluru, Delhi / NCR, Mumbai (All Areas)\\n(WFH during Covid)',\n",
       " 'Remote',\n",
       " 'Kolkata, Hyderabad/Secunderabad, Pune, Ahmedabad, Chennai, Bangalore/Bengaluru, Delhi / NCR, Mumbai (All Areas)',\n",
       " 'Delhi / NCR',\n",
       " 'Chennai',\n",
       " 'Chennai, Bangalore/Bengaluru, Delhi / NCR',\n",
       " 'Noida, Bangalore/Bengaluru, Delhi / NCR',\n",
       " 'Gurgaon/Gurugram',\n",
       " 'Gurgaon/Gurugram',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru\\n(WFH during Covid)',\n",
       " 'Hyderabad/Secunderabad(Jubilee Hills)',\n",
       " 'Gurgaon/Gurugram',\n",
       " 'New Delhi',\n",
       " 'Gurgaon/Gurugram',\n",
       " 'Gurgaon/Gurugram',\n",
       " 'Gurgaon/Gurugram',\n",
       " 'Gurgaon/Gurugram']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location = browser(\"//li[@class ='fleft grey-text br2 placeHolderLi location']\")\n",
    "Location =[]\n",
    "for i in location:\n",
    "    Location.append(i.text)\n",
    "Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Skills</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>Data Science / Business Analyst - Big Data Eng...</td>\n",
       "      <td>IT Skills\\nPython\\nData Science\\nMachine Learn...</td>\n",
       "      <td>Hyderabad/Secunderabad, Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tiger Analytics India LLP</td>\n",
       "      <td>Senior Analyst - Data Science</td>\n",
       "      <td>verbal communication\\nwritten\\nR\\npython\\nIT S...</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Trained Education</td>\n",
       "      <td>Data Science (Using ML with Python) Intern - D...</td>\n",
       "      <td>Data Science\\nR\\nTableau\\nMachine Learning\\nDe...</td>\n",
       "      <td>Remote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tata Consultancy Services Ltd.</td>\n",
       "      <td>Tcs Hiring For Data Science Developer - PAN India</td>\n",
       "      <td>Data Science\\nMachine Learning\\nPython\\nnltk\\n...</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Info Edge</td>\n",
       "      <td>Naukri is hiring Content Specialist-Data Scien...</td>\n",
       "      <td>Data Science\\nTechnology Management\\nContent C...</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AUTOMOTIVE ROBOTICS (INDIA) PRIVATE LIMITED</td>\n",
       "      <td>Data Analysis/Data Science</td>\n",
       "      <td>Power Bi\\nData Analysis\\nTableau\\nSQL Scriptin...</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tredence Analytics Solutions Private Limited</td>\n",
       "      <td>Hiring Data Science professionals For Tredence!</td>\n",
       "      <td>Data Science\\nPython\\nSQL\\nNltk\\nNatural Langu...</td>\n",
       "      <td>Chennai, Bangalore/Bengaluru, Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Synergistic Compusoft Private Limited</td>\n",
       "      <td>Hiring Data Science/Machine Learning Trainer-P...</td>\n",
       "      <td>Data Science\\nTrainer\\nMachine Learning\\ncommu...</td>\n",
       "      <td>Noida, Bangalore/Bengaluru, Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Accenture Solutions Pvt Ltd</td>\n",
       "      <td>ACN - Applied Intelligence - CC - Data Science...</td>\n",
       "      <td>requirements gathering\\nanalytical\\nIT Skills\\...</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Accenture Solutions Pvt Ltd</td>\n",
       "      <td>ACN - Applied Intelligence - CC - Data Science...</td>\n",
       "      <td>Computer science\\nVersion control\\nGIT\\nSAS\\nC...</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>Software Development Engineer III - Data Sciences</td>\n",
       "      <td>Supply chain\\nData analysis\\nLinux\\nCoding\\nMy...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>Software Development Engineer II - Data Sciences</td>\n",
       "      <td>Supply chain\\nData analysis\\nSoftware design\\n...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RANDSTAD INDIA PVT LTD</td>\n",
       "      <td>Business Intelligence Analyst with Data Scienc...</td>\n",
       "      <td>Business Intelligence\\nDW/BI\\nHadoop\\nBig Data...</td>\n",
       "      <td>Bangalore/Bengaluru\\n(WFH during Covid)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Step Next Private Limited</td>\n",
       "      <td>Senior Data Analyst(Data Science) - 2 &amp; PRO/Ma...</td>\n",
       "      <td>Data Science\\nMachine Learning\\nPython\\nIT Ski...</td>\n",
       "      <td>Hyderabad/Secunderabad(Jubilee Hills)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>IT Skills\\nPython\\nCloud\\nAWS\\nTableau\\nPower ...</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Resilient Innovations Private Limited</td>\n",
       "      <td>Urgent Hiring | Data Science Engineer | BharatPe</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>New Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Accenture Solutions Pvt Ltd</td>\n",
       "      <td>ACN - Applied Intelligence - CC - Data Science</td>\n",
       "      <td>Computer science\\nAnalytical\\nConsulting\\nMach...</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Accenture Solutions Pvt Ltd</td>\n",
       "      <td>ACN - Applied Intelligence - CC - Data Science...</td>\n",
       "      <td>IT Skills\\nPython\\nMachine Learning\\nCloud\\nAW...</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Accenture Solutions Pvt Ltd</td>\n",
       "      <td>ACN - Applied Intelligence - CC - Data Science...</td>\n",
       "      <td>IT Skills\\nPython\\nMachine Learning\\nCloud\\nAW...</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Accenture Solutions Pvt Ltd</td>\n",
       "      <td>ACN - Applied Intelligence - CC - Data Science...</td>\n",
       "      <td>analytical\\nComputer science\\nData analysis\\nV...</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Name  \\\n",
       "0             Inflexion Analytix Private Limited   \n",
       "1                      Tiger Analytics India LLP   \n",
       "2                         Data Trained Education   \n",
       "3                 Tata Consultancy Services Ltd.   \n",
       "4                                      Info Edge   \n",
       "5    AUTOMOTIVE ROBOTICS (INDIA) PRIVATE LIMITED   \n",
       "6   Tredence Analytics Solutions Private Limited   \n",
       "7          Synergistic Compusoft Private Limited   \n",
       "8                    Accenture Solutions Pvt Ltd   \n",
       "9                    Accenture Solutions Pvt Ltd   \n",
       "10             Flipkart Internet Private Limited   \n",
       "11             Flipkart Internet Private Limited   \n",
       "12                        RANDSTAD INDIA PVT LTD   \n",
       "13                     Step Next Private Limited   \n",
       "14                        IBM India Pvt. Limited   \n",
       "15         Resilient Innovations Private Limited   \n",
       "16                   Accenture Solutions Pvt Ltd   \n",
       "17                   Accenture Solutions Pvt Ltd   \n",
       "18                   Accenture Solutions Pvt Ltd   \n",
       "19                   Accenture Solutions Pvt Ltd   \n",
       "\n",
       "                                          Designation  \\\n",
       "0   Data Science / Business Analyst - Big Data Eng...   \n",
       "1                       Senior Analyst - Data Science   \n",
       "2   Data Science (Using ML with Python) Intern - D...   \n",
       "3   Tcs Hiring For Data Science Developer - PAN India   \n",
       "4   Naukri is hiring Content Specialist-Data Scien...   \n",
       "5                          Data Analysis/Data Science   \n",
       "6     Hiring Data Science professionals For Tredence!   \n",
       "7   Hiring Data Science/Machine Learning Trainer-P...   \n",
       "8   ACN - Applied Intelligence - CC - Data Science...   \n",
       "9   ACN - Applied Intelligence - CC - Data Science...   \n",
       "10  Software Development Engineer III - Data Sciences   \n",
       "11   Software Development Engineer II - Data Sciences   \n",
       "12  Business Intelligence Analyst with Data Scienc...   \n",
       "13  Senior Data Analyst(Data Science) - 2 & PRO/Ma...   \n",
       "14                                       Data Science   \n",
       "15   Urgent Hiring | Data Science Engineer | BharatPe   \n",
       "16     ACN - Applied Intelligence - CC - Data Science   \n",
       "17  ACN - Applied Intelligence - CC - Data Science...   \n",
       "18  ACN - Applied Intelligence - CC - Data Science...   \n",
       "19  ACN - Applied Intelligence - CC - Data Science...   \n",
       "\n",
       "                                               Skills  \\\n",
       "0   IT Skills\\nPython\\nData Science\\nMachine Learn...   \n",
       "1   verbal communication\\nwritten\\nR\\npython\\nIT S...   \n",
       "2   Data Science\\nR\\nTableau\\nMachine Learning\\nDe...   \n",
       "3   Data Science\\nMachine Learning\\nPython\\nnltk\\n...   \n",
       "4   Data Science\\nTechnology Management\\nContent C...   \n",
       "5   Power Bi\\nData Analysis\\nTableau\\nSQL Scriptin...   \n",
       "6   Data Science\\nPython\\nSQL\\nNltk\\nNatural Langu...   \n",
       "7   Data Science\\nTrainer\\nMachine Learning\\ncommu...   \n",
       "8   requirements gathering\\nanalytical\\nIT Skills\\...   \n",
       "9   Computer science\\nVersion control\\nGIT\\nSAS\\nC...   \n",
       "10  Supply chain\\nData analysis\\nLinux\\nCoding\\nMy...   \n",
       "11  Supply chain\\nData analysis\\nSoftware design\\n...   \n",
       "12  Business Intelligence\\nDW/BI\\nHadoop\\nBig Data...   \n",
       "13  Data Science\\nMachine Learning\\nPython\\nIT Ski...   \n",
       "14  IT Skills\\nPython\\nCloud\\nAWS\\nTableau\\nPower ...   \n",
       "15                                       Data Science   \n",
       "16  Computer science\\nAnalytical\\nConsulting\\nMach...   \n",
       "17  IT Skills\\nPython\\nMachine Learning\\nCloud\\nAW...   \n",
       "18  IT Skills\\nPython\\nMachine Learning\\nCloud\\nAW...   \n",
       "19  analytical\\nComputer science\\nData analysis\\nV...   \n",
       "\n",
       "                                             Location  \n",
       "0                     Hyderabad/Secunderabad, Chennai  \n",
       "1   Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...  \n",
       "2                                              Remote  \n",
       "3   Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...  \n",
       "4                                         Delhi / NCR  \n",
       "5                                             Chennai  \n",
       "6           Chennai, Bangalore/Bengaluru, Delhi / NCR  \n",
       "7             Noida, Bangalore/Bengaluru, Delhi / NCR  \n",
       "8                                    Gurgaon/Gurugram  \n",
       "9                                    Gurgaon/Gurugram  \n",
       "10                                Bangalore/Bengaluru  \n",
       "11                                Bangalore/Bengaluru  \n",
       "12            Bangalore/Bengaluru\\n(WFH during Covid)  \n",
       "13              Hyderabad/Secunderabad(Jubilee Hills)  \n",
       "14                                   Gurgaon/Gurugram  \n",
       "15                                          New Delhi  \n",
       "16                                   Gurgaon/Gurugram  \n",
       "17                                   Gurgaon/Gurugram  \n",
       "18                                   Gurgaon/Gurugram  \n",
       "19                                   Gurgaon/Gurugram  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naukri = pd.DataFrame({})\n",
    "naukri['Name'] = Name\n",
    "naukri['Designation'] = Designation\n",
    "naukri['Skills'] = Skills\n",
    "naukri['Location'] = Location\n",
    "\n",
    "naukri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Scrape the details of Highest selling novels.Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey\u0002compare/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = (\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/\")\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"2 Harry Potter and the Deathly Hallows Rowling, J.K. 4,475,152 Bloomsbury Children's Fiction\",\n",
       " \"4 Harry Potter and the Order of the Phoenix Rowling, J.K. 4,179,479 Bloomsbury Children's Fiction\",\n",
       " \"6 Harry Potter and the Goblet of Fire Rowling, J.K. 3,583,215 Bloomsbury Children's Fiction\",\n",
       " \"8 Harry Potter and the Prisoner of Azkaban Rowling, J.K. 3,377,906 Bloomsbury Children's Fiction\",\n",
       " \"10 Harry Potter and the Half-blood Prince:Children's Edition Rowling, J.K. 2,950,264 Bloomsbury Children's Fiction\",\n",
       " '12 Twilight Meyer, Stephenie 2,315,405 Little, Brown Book Young Adult Fiction',\n",
       " '14 Fifty Shades Freed James, E. L. 2,193,928 Random House Romance & Sagas',\n",
       " '16 New Moon Meyer, Stephenie 2,152,737 Little, Brown Book Young Adult Fiction',\n",
       " '18 Eclipse Meyer, Stephenie 2,052,876 Little, Brown Book Young Adult Fiction',\n",
       " '20 Curious Incident of the Dog in the Night-time,The Haddon, Mark 1,979,552 Random House General & Literary Fiction',\n",
       " '22 Short History of Nearly Everything,A Bryson, Bill 1,852,919 Transworld Popular Science',\n",
       " '24 Breaking Dawn Meyer, Stephenie 1,787,118 Little, Brown Book Young Adult Fiction',\n",
       " '26 Gruffalo,The Donaldson, Julia 1,781,269 Pan Macmillan Picture Books',\n",
       " '28 Kite Runner,The Hosseini, Khaled 1,629,119 Bloomsbury General & Literary Fiction',\n",
       " '30 Thousand Splendid Suns,A Hosseini, Khaled 1,583,992 Bloomsbury General & Literary Fiction',\n",
       " \"32 Time Traveler's Wife,The Niffenegger, Audrey 1,546,886 Random House General & Literary Fiction\",\n",
       " \"34 Bridget Jones's Diary:A Novel Fielding, Helen 1,508,205 Pan Macmillan General & Literary Fiction\",\n",
       " \"36 Captain Corelli's Mandolin Bernieres, Louis de 1,352,318 Random House General & Literary Fiction\",\n",
       " '38 Life of Pi Martel, Yann 1,310,176 Canongate General & Literary Fiction',\n",
       " '40 Child Called It,A Pelzer, Dave 1,217,712 Orion Autobiography: General',\n",
       " \"42 Angela's Ashes:A Memoir of a Childhood McCourt, Frank 1,204,058 HarperCollins Autobiography: General\",\n",
       " '44 Northern Lights:His Dark Materials S. Pullman, Philip 1,181,503 Scholastic Ltd. Young Adult Fiction',\n",
       " '46 Harry Potter and the Half-blood Prince Rowling, J.K. 1,153,181 Bloomsbury Science Fiction & Fantasy',\n",
       " '48 Man and Boy Parsons, Tony 1,130,802 HarperCollins General & Literary Fiction',\n",
       " \"50 No.1 Ladies' Detective Agency,The:No.1 Ladies' Detective Agency S. McCall Smith, Alexander 1,115,549 Little, Brown Book Crime, Thriller & Adventure\",\n",
       " '52 PS, I Love You Ahern, Cecelia 1,107,379 HarperCollins General & Literary Fiction',\n",
       " '54 Shadow of the Wind,The Zafon, Carlos Ruiz 1,092,349 Orion General & Literary Fiction',\n",
       " '56 Broker,The Grisham, John 1,087,262 Random House Crime, Thriller & Adventure',\n",
       " '58 Subtle Knife,The:His Dark Materials S. Pullman, Philip 1,037,160 Scholastic Ltd. Young Adult Fiction',\n",
       " \"60 Delia's How to Cook:(Bk.1) Smith, Delia 1,015,956 Random House Food & Drink: General\",\n",
       " '62 Boy in the Striped Pyjamas,The Boyne, John 1,004,414 Random House Childrens Books G Young Adult Fiction',\n",
       " '64 Amber Spyglass,The:His Dark Materials S. Pullman, Philip 1,002,314 Scholastic Ltd. Young Adult Fiction',\n",
       " '66 Men are from Mars, Women are from Venus:A Practical Guide for Improvin Gray, John 992,846 HarperCollins Popular Culture & Media: General Interest',\n",
       " '68 Short History of Tractors in Ukrainian,A Lewycka, Marina 986,115 Penguin General & Literary Fiction',\n",
       " '70 Lord of the Rings,The Tolkien, J. R. R. 967,466 HarperCollins Science Fiction & Fantasy',\n",
       " '72 Interpretation of Murder,The Rubenfeld, Jed 962,515 Headline Crime, Thriller & Adventure',\n",
       " '74 Alchemist,The:A Fable About Following Your Dream Coelho, Paulo 956,114 HarperCollins General & Literary Fiction',\n",
       " '76 Notes from a Small Island Bryson, Bill 931,312 Transworld Travel Writing',\n",
       " '78 Bridget Jones: The Edge of Reason Fielding, Helen 924,695 Pan Macmillan General & Literary Fiction',\n",
       " '80 I Can Make You Thin McKenna, Paul 905,086 Transworld Fitness & Diet',\n",
       " '82 Summons,The Grisham, John 869,671 Random House Crime, Thriller & Adventure',\n",
       " '84 Nigella Express Lawson, Nigella 862,602 Random House Food & Drink: General',\n",
       " \"86 Memory Keeper's Daughter,The Edwards, Kim 845,858 Penguin General & Literary Fiction\",\n",
       " '88 About a Boy Hornby, Nick 828,215 Penguin General & Literary Fiction',\n",
       " '90 God Delusion,The Dawkins, Richard 816,907 Transworld Popular Science',\n",
       " '92 White Teeth Smith, Zadie 815,586 Penguin General & Literary Fiction',\n",
       " '94 Book Thief,The Zusak, Markus 809,641 Transworld General & Literary Fiction',\n",
       " '96 Ghost,The Harris, Robert 807,311 Random House General & Literary Fiction',\n",
       " '98 Hunger Games,The:Hunger Games Trilogy Collins, Suzanne 792,187 Scholastic Ltd. Young Adult Fiction',\n",
       " \"100 Jamie's Ministry of Food:Anyone Can Learn to Cook in 24 Hours Oliver, Jamie 791,095 Penguin Food & Drink: General\"]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book = browser(\"//tr[@class = 'odd']\")\n",
    "Book =[]\n",
    "for i in book:\n",
    "    Book.append(i.text)\n",
    "Book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"2 Harry Potter and the Deathly Hallows Rowling, J.K. 4,475,152 Bloomsbury Children's Fiction\",\n",
       " \"4 Harry Potter and the Order of the Phoenix Rowling, J.K. 4,179,479 Bloomsbury Children's Fiction\",\n",
       " \"6 Harry Potter and the Goblet of Fire Rowling, J.K. 3,583,215 Bloomsbury Children's Fiction\",\n",
       " \"8 Harry Potter and the Prisoner of Azkaban Rowling, J.K. 3,377,906 Bloomsbury Children's Fiction\",\n",
       " \"10 Harry Potter and the Half-blood Prince:Children's Edition Rowling, J.K. 2,950,264 Bloomsbury Children's Fiction\",\n",
       " '12 Twilight Meyer, Stephenie 2,315,405 Little, Brown Book Young Adult Fiction',\n",
       " '14 Fifty Shades Freed James, E. L. 2,193,928 Random House Romance & Sagas',\n",
       " '16 New Moon Meyer, Stephenie 2,152,737 Little, Brown Book Young Adult Fiction',\n",
       " '18 Eclipse Meyer, Stephenie 2,052,876 Little, Brown Book Young Adult Fiction',\n",
       " '20 Curious Incident of the Dog in the Night-time,The Haddon, Mark 1,979,552 Random House General & Literary Fiction',\n",
       " '22 Short History of Nearly Everything,A Bryson, Bill 1,852,919 Transworld Popular Science',\n",
       " '24 Breaking Dawn Meyer, Stephenie 1,787,118 Little, Brown Book Young Adult Fiction',\n",
       " '26 Gruffalo,The Donaldson, Julia 1,781,269 Pan Macmillan Picture Books',\n",
       " '28 Kite Runner,The Hosseini, Khaled 1,629,119 Bloomsbury General & Literary Fiction',\n",
       " '30 Thousand Splendid Suns,A Hosseini, Khaled 1,583,992 Bloomsbury General & Literary Fiction',\n",
       " \"32 Time Traveler's Wife,The Niffenegger, Audrey 1,546,886 Random House General & Literary Fiction\",\n",
       " \"34 Bridget Jones's Diary:A Novel Fielding, Helen 1,508,205 Pan Macmillan General & Literary Fiction\",\n",
       " \"36 Captain Corelli's Mandolin Bernieres, Louis de 1,352,318 Random House General & Literary Fiction\",\n",
       " '38 Life of Pi Martel, Yann 1,310,176 Canongate General & Literary Fiction',\n",
       " '40 Child Called It,A Pelzer, Dave 1,217,712 Orion Autobiography: General',\n",
       " \"42 Angela's Ashes:A Memoir of a Childhood McCourt, Frank 1,204,058 HarperCollins Autobiography: General\",\n",
       " '44 Northern Lights:His Dark Materials S. Pullman, Philip 1,181,503 Scholastic Ltd. Young Adult Fiction',\n",
       " '46 Harry Potter and the Half-blood Prince Rowling, J.K. 1,153,181 Bloomsbury Science Fiction & Fantasy',\n",
       " '48 Man and Boy Parsons, Tony 1,130,802 HarperCollins General & Literary Fiction',\n",
       " \"50 No.1 Ladies' Detective Agency,The:No.1 Ladies' Detective Agency S. McCall Smith, Alexander 1,115,549 Little, Brown Book Crime, Thriller & Adventure\",\n",
       " '52 PS, I Love You Ahern, Cecelia 1,107,379 HarperCollins General & Literary Fiction',\n",
       " '54 Shadow of the Wind,The Zafon, Carlos Ruiz 1,092,349 Orion General & Literary Fiction',\n",
       " '56 Broker,The Grisham, John 1,087,262 Random House Crime, Thriller & Adventure',\n",
       " '58 Subtle Knife,The:His Dark Materials S. Pullman, Philip 1,037,160 Scholastic Ltd. Young Adult Fiction',\n",
       " \"60 Delia's How to Cook:(Bk.1) Smith, Delia 1,015,956 Random House Food & Drink: General\",\n",
       " '62 Boy in the Striped Pyjamas,The Boyne, John 1,004,414 Random House Childrens Books G Young Adult Fiction',\n",
       " '64 Amber Spyglass,The:His Dark Materials S. Pullman, Philip 1,002,314 Scholastic Ltd. Young Adult Fiction',\n",
       " '66 Men are from Mars, Women are from Venus:A Practical Guide for Improvin Gray, John 992,846 HarperCollins Popular Culture & Media: General Interest',\n",
       " '68 Short History of Tractors in Ukrainian,A Lewycka, Marina 986,115 Penguin General & Literary Fiction',\n",
       " '70 Lord of the Rings,The Tolkien, J. R. R. 967,466 HarperCollins Science Fiction & Fantasy',\n",
       " '72 Interpretation of Murder,The Rubenfeld, Jed 962,515 Headline Crime, Thriller & Adventure',\n",
       " '74 Alchemist,The:A Fable About Following Your Dream Coelho, Paulo 956,114 HarperCollins General & Literary Fiction',\n",
       " '76 Notes from a Small Island Bryson, Bill 931,312 Transworld Travel Writing',\n",
       " '78 Bridget Jones: The Edge of Reason Fielding, Helen 924,695 Pan Macmillan General & Literary Fiction',\n",
       " '80 I Can Make You Thin McKenna, Paul 905,086 Transworld Fitness & Diet',\n",
       " '82 Summons,The Grisham, John 869,671 Random House Crime, Thriller & Adventure',\n",
       " '84 Nigella Express Lawson, Nigella 862,602 Random House Food & Drink: General',\n",
       " \"86 Memory Keeper's Daughter,The Edwards, Kim 845,858 Penguin General & Literary Fiction\",\n",
       " '88 About a Boy Hornby, Nick 828,215 Penguin General & Literary Fiction',\n",
       " '90 God Delusion,The Dawkins, Richard 816,907 Transworld Popular Science',\n",
       " '92 White Teeth Smith, Zadie 815,586 Penguin General & Literary Fiction',\n",
       " '94 Book Thief,The Zusak, Markus 809,641 Transworld General & Literary Fiction',\n",
       " '96 Ghost,The Harris, Robert 807,311 Random House General & Literary Fiction',\n",
       " '98 Hunger Games,The:Hunger Games Trilogy Collins, Suzanne 792,187 Scholastic Ltd. Young Adult Fiction',\n",
       " \"100 Jamie's Ministry of Food:Anyone Can Learn to Cook in 24 Hours Oliver, Jamie 791,095 Penguin Food & Drink: General\"]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author = browser(\"//tr[@class ='odd']\")\n",
    "Author =[]\n",
    "for i in author:\n",
    "    Author.append(i.text)\n",
    "Author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book_Name</th>\n",
       "      <th>Author_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 Harry Potter and the Deathly Hallows Rowling...</td>\n",
       "      <td>2 Harry Potter and the Deathly Hallows Rowling...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4 Harry Potter and the Order of the Phoenix Ro...</td>\n",
       "      <td>4 Harry Potter and the Order of the Phoenix Ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6 Harry Potter and the Goblet of Fire Rowling,...</td>\n",
       "      <td>6 Harry Potter and the Goblet of Fire Rowling,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8 Harry Potter and the Prisoner of Azkaban Row...</td>\n",
       "      <td>8 Harry Potter and the Prisoner of Azkaban Row...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10 Harry Potter and the Half-blood Prince:Chil...</td>\n",
       "      <td>10 Harry Potter and the Half-blood Prince:Chil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12 Twilight Meyer, Stephenie 2,315,405 Little,...</td>\n",
       "      <td>12 Twilight Meyer, Stephenie 2,315,405 Little,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14 Fifty Shades Freed James, E. L. 2,193,928 R...</td>\n",
       "      <td>14 Fifty Shades Freed James, E. L. 2,193,928 R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16 New Moon Meyer, Stephenie 2,152,737 Little,...</td>\n",
       "      <td>16 New Moon Meyer, Stephenie 2,152,737 Little,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18 Eclipse Meyer, Stephenie 2,052,876 Little, ...</td>\n",
       "      <td>18 Eclipse Meyer, Stephenie 2,052,876 Little, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20 Curious Incident of the Dog in the Night-ti...</td>\n",
       "      <td>20 Curious Incident of the Dog in the Night-ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>22 Short History of Nearly Everything,A Bryson...</td>\n",
       "      <td>22 Short History of Nearly Everything,A Bryson...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>24 Breaking Dawn Meyer, Stephenie 1,787,118 Li...</td>\n",
       "      <td>24 Breaking Dawn Meyer, Stephenie 1,787,118 Li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>26 Gruffalo,The Donaldson, Julia 1,781,269 Pan...</td>\n",
       "      <td>26 Gruffalo,The Donaldson, Julia 1,781,269 Pan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>28 Kite Runner,The Hosseini, Khaled 1,629,119 ...</td>\n",
       "      <td>28 Kite Runner,The Hosseini, Khaled 1,629,119 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>30 Thousand Splendid Suns,A Hosseini, Khaled 1...</td>\n",
       "      <td>30 Thousand Splendid Suns,A Hosseini, Khaled 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>32 Time Traveler's Wife,The Niffenegger, Audre...</td>\n",
       "      <td>32 Time Traveler's Wife,The Niffenegger, Audre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>34 Bridget Jones's Diary:A Novel Fielding, Hel...</td>\n",
       "      <td>34 Bridget Jones's Diary:A Novel Fielding, Hel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>36 Captain Corelli's Mandolin Bernieres, Louis...</td>\n",
       "      <td>36 Captain Corelli's Mandolin Bernieres, Louis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>38 Life of Pi Martel, Yann 1,310,176 Canongate...</td>\n",
       "      <td>38 Life of Pi Martel, Yann 1,310,176 Canongate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>40 Child Called It,A Pelzer, Dave 1,217,712 Or...</td>\n",
       "      <td>40 Child Called It,A Pelzer, Dave 1,217,712 Or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>42 Angela's Ashes:A Memoir of a Childhood McCo...</td>\n",
       "      <td>42 Angela's Ashes:A Memoir of a Childhood McCo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>44 Northern Lights:His Dark Materials S. Pullm...</td>\n",
       "      <td>44 Northern Lights:His Dark Materials S. Pullm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>46 Harry Potter and the Half-blood Prince Rowl...</td>\n",
       "      <td>46 Harry Potter and the Half-blood Prince Rowl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>48 Man and Boy Parsons, Tony 1,130,802 HarperC...</td>\n",
       "      <td>48 Man and Boy Parsons, Tony 1,130,802 HarperC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>50 No.1 Ladies' Detective Agency,The:No.1 Ladi...</td>\n",
       "      <td>50 No.1 Ladies' Detective Agency,The:No.1 Ladi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>52 PS, I Love You Ahern, Cecelia 1,107,379 Har...</td>\n",
       "      <td>52 PS, I Love You Ahern, Cecelia 1,107,379 Har...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>54 Shadow of the Wind,The Zafon, Carlos Ruiz 1...</td>\n",
       "      <td>54 Shadow of the Wind,The Zafon, Carlos Ruiz 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>56 Broker,The Grisham, John 1,087,262 Random H...</td>\n",
       "      <td>56 Broker,The Grisham, John 1,087,262 Random H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>58 Subtle Knife,The:His Dark Materials S. Pull...</td>\n",
       "      <td>58 Subtle Knife,The:His Dark Materials S. Pull...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>60 Delia's How to Cook:(Bk.1) Smith, Delia 1,0...</td>\n",
       "      <td>60 Delia's How to Cook:(Bk.1) Smith, Delia 1,0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>62 Boy in the Striped Pyjamas,The Boyne, John ...</td>\n",
       "      <td>62 Boy in the Striped Pyjamas,The Boyne, John ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>64 Amber Spyglass,The:His Dark Materials S. Pu...</td>\n",
       "      <td>64 Amber Spyglass,The:His Dark Materials S. Pu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>66 Men are from Mars, Women are from Venus:A P...</td>\n",
       "      <td>66 Men are from Mars, Women are from Venus:A P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>68 Short History of Tractors in Ukrainian,A Le...</td>\n",
       "      <td>68 Short History of Tractors in Ukrainian,A Le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>70 Lord of the Rings,The Tolkien, J. R. R. 967...</td>\n",
       "      <td>70 Lord of the Rings,The Tolkien, J. R. R. 967...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>72 Interpretation of Murder,The Rubenfeld, Jed...</td>\n",
       "      <td>72 Interpretation of Murder,The Rubenfeld, Jed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>74 Alchemist,The:A Fable About Following Your ...</td>\n",
       "      <td>74 Alchemist,The:A Fable About Following Your ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>76 Notes from a Small Island Bryson, Bill 931,...</td>\n",
       "      <td>76 Notes from a Small Island Bryson, Bill 931,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>78 Bridget Jones: The Edge of Reason Fielding,...</td>\n",
       "      <td>78 Bridget Jones: The Edge of Reason Fielding,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>80 I Can Make You Thin McKenna, Paul 905,086 T...</td>\n",
       "      <td>80 I Can Make You Thin McKenna, Paul 905,086 T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>82 Summons,The Grisham, John 869,671 Random Ho...</td>\n",
       "      <td>82 Summons,The Grisham, John 869,671 Random Ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>84 Nigella Express Lawson, Nigella 862,602 Ran...</td>\n",
       "      <td>84 Nigella Express Lawson, Nigella 862,602 Ran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>86 Memory Keeper's Daughter,The Edwards, Kim 8...</td>\n",
       "      <td>86 Memory Keeper's Daughter,The Edwards, Kim 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>88 About a Boy Hornby, Nick 828,215 Penguin Ge...</td>\n",
       "      <td>88 About a Boy Hornby, Nick 828,215 Penguin Ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>90 God Delusion,The Dawkins, Richard 816,907 T...</td>\n",
       "      <td>90 God Delusion,The Dawkins, Richard 816,907 T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>92 White Teeth Smith, Zadie 815,586 Penguin Ge...</td>\n",
       "      <td>92 White Teeth Smith, Zadie 815,586 Penguin Ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>94 Book Thief,The Zusak, Markus 809,641 Transw...</td>\n",
       "      <td>94 Book Thief,The Zusak, Markus 809,641 Transw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>96 Ghost,The Harris, Robert 807,311 Random Hou...</td>\n",
       "      <td>96 Ghost,The Harris, Robert 807,311 Random Hou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>98 Hunger Games,The:Hunger Games Trilogy Colli...</td>\n",
       "      <td>98 Hunger Games,The:Hunger Games Trilogy Colli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>100 Jamie's Ministry of Food:Anyone Can Learn ...</td>\n",
       "      <td>100 Jamie's Ministry of Food:Anyone Can Learn ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book_Name  \\\n",
       "0   2 Harry Potter and the Deathly Hallows Rowling...   \n",
       "1   4 Harry Potter and the Order of the Phoenix Ro...   \n",
       "2   6 Harry Potter and the Goblet of Fire Rowling,...   \n",
       "3   8 Harry Potter and the Prisoner of Azkaban Row...   \n",
       "4   10 Harry Potter and the Half-blood Prince:Chil...   \n",
       "5   12 Twilight Meyer, Stephenie 2,315,405 Little,...   \n",
       "6   14 Fifty Shades Freed James, E. L. 2,193,928 R...   \n",
       "7   16 New Moon Meyer, Stephenie 2,152,737 Little,...   \n",
       "8   18 Eclipse Meyer, Stephenie 2,052,876 Little, ...   \n",
       "9   20 Curious Incident of the Dog in the Night-ti...   \n",
       "10  22 Short History of Nearly Everything,A Bryson...   \n",
       "11  24 Breaking Dawn Meyer, Stephenie 1,787,118 Li...   \n",
       "12  26 Gruffalo,The Donaldson, Julia 1,781,269 Pan...   \n",
       "13  28 Kite Runner,The Hosseini, Khaled 1,629,119 ...   \n",
       "14  30 Thousand Splendid Suns,A Hosseini, Khaled 1...   \n",
       "15  32 Time Traveler's Wife,The Niffenegger, Audre...   \n",
       "16  34 Bridget Jones's Diary:A Novel Fielding, Hel...   \n",
       "17  36 Captain Corelli's Mandolin Bernieres, Louis...   \n",
       "18  38 Life of Pi Martel, Yann 1,310,176 Canongate...   \n",
       "19  40 Child Called It,A Pelzer, Dave 1,217,712 Or...   \n",
       "20  42 Angela's Ashes:A Memoir of a Childhood McCo...   \n",
       "21  44 Northern Lights:His Dark Materials S. Pullm...   \n",
       "22  46 Harry Potter and the Half-blood Prince Rowl...   \n",
       "23  48 Man and Boy Parsons, Tony 1,130,802 HarperC...   \n",
       "24  50 No.1 Ladies' Detective Agency,The:No.1 Ladi...   \n",
       "25  52 PS, I Love You Ahern, Cecelia 1,107,379 Har...   \n",
       "26  54 Shadow of the Wind,The Zafon, Carlos Ruiz 1...   \n",
       "27  56 Broker,The Grisham, John 1,087,262 Random H...   \n",
       "28  58 Subtle Knife,The:His Dark Materials S. Pull...   \n",
       "29  60 Delia's How to Cook:(Bk.1) Smith, Delia 1,0...   \n",
       "30  62 Boy in the Striped Pyjamas,The Boyne, John ...   \n",
       "31  64 Amber Spyglass,The:His Dark Materials S. Pu...   \n",
       "32  66 Men are from Mars, Women are from Venus:A P...   \n",
       "33  68 Short History of Tractors in Ukrainian,A Le...   \n",
       "34  70 Lord of the Rings,The Tolkien, J. R. R. 967...   \n",
       "35  72 Interpretation of Murder,The Rubenfeld, Jed...   \n",
       "36  74 Alchemist,The:A Fable About Following Your ...   \n",
       "37  76 Notes from a Small Island Bryson, Bill 931,...   \n",
       "38  78 Bridget Jones: The Edge of Reason Fielding,...   \n",
       "39  80 I Can Make You Thin McKenna, Paul 905,086 T...   \n",
       "40  82 Summons,The Grisham, John 869,671 Random Ho...   \n",
       "41  84 Nigella Express Lawson, Nigella 862,602 Ran...   \n",
       "42  86 Memory Keeper's Daughter,The Edwards, Kim 8...   \n",
       "43  88 About a Boy Hornby, Nick 828,215 Penguin Ge...   \n",
       "44  90 God Delusion,The Dawkins, Richard 816,907 T...   \n",
       "45  92 White Teeth Smith, Zadie 815,586 Penguin Ge...   \n",
       "46  94 Book Thief,The Zusak, Markus 809,641 Transw...   \n",
       "47  96 Ghost,The Harris, Robert 807,311 Random Hou...   \n",
       "48  98 Hunger Games,The:Hunger Games Trilogy Colli...   \n",
       "49  100 Jamie's Ministry of Food:Anyone Can Learn ...   \n",
       "\n",
       "                                          Author_Name  \n",
       "0   2 Harry Potter and the Deathly Hallows Rowling...  \n",
       "1   4 Harry Potter and the Order of the Phoenix Ro...  \n",
       "2   6 Harry Potter and the Goblet of Fire Rowling,...  \n",
       "3   8 Harry Potter and the Prisoner of Azkaban Row...  \n",
       "4   10 Harry Potter and the Half-blood Prince:Chil...  \n",
       "5   12 Twilight Meyer, Stephenie 2,315,405 Little,...  \n",
       "6   14 Fifty Shades Freed James, E. L. 2,193,928 R...  \n",
       "7   16 New Moon Meyer, Stephenie 2,152,737 Little,...  \n",
       "8   18 Eclipse Meyer, Stephenie 2,052,876 Little, ...  \n",
       "9   20 Curious Incident of the Dog in the Night-ti...  \n",
       "10  22 Short History of Nearly Everything,A Bryson...  \n",
       "11  24 Breaking Dawn Meyer, Stephenie 1,787,118 Li...  \n",
       "12  26 Gruffalo,The Donaldson, Julia 1,781,269 Pan...  \n",
       "13  28 Kite Runner,The Hosseini, Khaled 1,629,119 ...  \n",
       "14  30 Thousand Splendid Suns,A Hosseini, Khaled 1...  \n",
       "15  32 Time Traveler's Wife,The Niffenegger, Audre...  \n",
       "16  34 Bridget Jones's Diary:A Novel Fielding, Hel...  \n",
       "17  36 Captain Corelli's Mandolin Bernieres, Louis...  \n",
       "18  38 Life of Pi Martel, Yann 1,310,176 Canongate...  \n",
       "19  40 Child Called It,A Pelzer, Dave 1,217,712 Or...  \n",
       "20  42 Angela's Ashes:A Memoir of a Childhood McCo...  \n",
       "21  44 Northern Lights:His Dark Materials S. Pullm...  \n",
       "22  46 Harry Potter and the Half-blood Prince Rowl...  \n",
       "23  48 Man and Boy Parsons, Tony 1,130,802 HarperC...  \n",
       "24  50 No.1 Ladies' Detective Agency,The:No.1 Ladi...  \n",
       "25  52 PS, I Love You Ahern, Cecelia 1,107,379 Har...  \n",
       "26  54 Shadow of the Wind,The Zafon, Carlos Ruiz 1...  \n",
       "27  56 Broker,The Grisham, John 1,087,262 Random H...  \n",
       "28  58 Subtle Knife,The:His Dark Materials S. Pull...  \n",
       "29  60 Delia's How to Cook:(Bk.1) Smith, Delia 1,0...  \n",
       "30  62 Boy in the Striped Pyjamas,The Boyne, John ...  \n",
       "31  64 Amber Spyglass,The:His Dark Materials S. Pu...  \n",
       "32  66 Men are from Mars, Women are from Venus:A P...  \n",
       "33  68 Short History of Tractors in Ukrainian,A Le...  \n",
       "34  70 Lord of the Rings,The Tolkien, J. R. R. 967...  \n",
       "35  72 Interpretation of Murder,The Rubenfeld, Jed...  \n",
       "36  74 Alchemist,The:A Fable About Following Your ...  \n",
       "37  76 Notes from a Small Island Bryson, Bill 931,...  \n",
       "38  78 Bridget Jones: The Edge of Reason Fielding,...  \n",
       "39  80 I Can Make You Thin McKenna, Paul 905,086 T...  \n",
       "40  82 Summons,The Grisham, John 869,671 Random Ho...  \n",
       "41  84 Nigella Express Lawson, Nigella 862,602 Ran...  \n",
       "42  86 Memory Keeper's Daughter,The Edwards, Kim 8...  \n",
       "43  88 About a Boy Hornby, Nick 828,215 Penguin Ge...  \n",
       "44  90 God Delusion,The Dawkins, Richard 816,907 T...  \n",
       "45  92 White Teeth Smith, Zadie 815,586 Penguin Ge...  \n",
       "46  94 Book Thief,The Zusak, Markus 809,641 Transw...  \n",
       "47  96 Ghost,The Harris, Robert 807,311 Random Hou...  \n",
       "48  98 Hunger Games,The:Hunger Games Trilogy Colli...  \n",
       "49  100 Jamie's Ministry of Food:Anyone Can Learn ...  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "novels = pd.DataFrame({})\n",
    "novels['Book_Name'] = Book\n",
    "novels['Author_Name'] = Author\n",
    "novels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Scrape the details most watched tv series of all time from imdb.com. Url = https://www.imdb.com/list/ls095964455/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "url =(\"https://www.imdb.com/list/ls095964455/\")\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. Game of Thrones (2011â€“2019)',\n",
       " '2. Stranger Things (2016â€“ )',\n",
       " '3. The Walking Dead (2010â€“2022)',\n",
       " '4. 13 Reasons Why (2017â€“2020)',\n",
       " '5. The 100 (2014â€“2020)',\n",
       " '6. Orange Is the New Black (2013â€“2019)',\n",
       " '7. Riverdale (2017â€“ )',\n",
       " \"8. Grey's Anatomy (2005â€“ )\",\n",
       " '9. The Flash (2014â€“ )',\n",
       " '10. Arrow (2012â€“2020)',\n",
       " '11. Money Heist (2017â€“2021)',\n",
       " '12. The Big Bang Theory (2007â€“2019)',\n",
       " '13. Black Mirror (2011â€“ )',\n",
       " '14. Sherlock (2010â€“2017)',\n",
       " '15. Vikings (2013â€“2020)',\n",
       " '16. Pretty Little Liars (2010â€“2017)',\n",
       " '17. The Vampire Diaries (2009â€“2017)',\n",
       " '18. American Horror Story (2011â€“ )',\n",
       " '19. Breaking Bad (2008â€“2013)',\n",
       " '20. Lucifer (2016â€“2021)',\n",
       " '21. Supernatural (2005â€“2020)',\n",
       " '22. Prison Break (2005â€“2017)',\n",
       " '23. How to Get Away with Murder (2014â€“2020)',\n",
       " '24. Teen Wolf (2011â€“2017)',\n",
       " '25. The Simpsons (1989â€“ )',\n",
       " '26. Once Upon a Time (2011â€“2018)',\n",
       " '27. Narcos (2015â€“2017)',\n",
       " '28. Daredevil (2015â€“2018)',\n",
       " '29. Friends (1994â€“2004)',\n",
       " '30. How I Met Your Mother (2005â€“2014)',\n",
       " '31. Suits (2011â€“2019)',\n",
       " '32. Mr. Robot (2015â€“2019)',\n",
       " '33. The Originals (2013â€“2018)',\n",
       " '34. Supergirl (2015â€“2021)',\n",
       " '35. Gossip Girl (2007â€“2012)',\n",
       " '36. Sense8 (2015â€“2018)',\n",
       " '37. Gotham (2014â€“2019)',\n",
       " '38. Westworld (2016â€“ )',\n",
       " '39. Jessica Jones (2015â€“2019)',\n",
       " '40. Modern Family (2009â€“2020)',\n",
       " '41. Rick and Morty (2013â€“ )',\n",
       " '42. Shadowhunters (2016â€“2019)',\n",
       " '43. The End of the F***ing World (2017â€“2019)',\n",
       " '44. House of Cards (2013â€“2018)',\n",
       " '45. Dark (2017â€“2020)',\n",
       " '46. Elite (2018â€“ )',\n",
       " '47. Sex Education (2019â€“ )',\n",
       " '48. Shameless (2011â€“2021)',\n",
       " '49. New Girl (2011â€“2018)',\n",
       " '50. Agents of S.H.I.E.L.D. (2013â€“2020)',\n",
       " '51. You (2018â€“ )',\n",
       " '52. Dexter (2006â€“2013)',\n",
       " '53. Fear the Walking Dead (2015â€“ )',\n",
       " '54. Family Guy (1999â€“ )',\n",
       " '55. The Blacklist (2013â€“ )',\n",
       " '56. Lost (2004â€“2010)',\n",
       " '57. Peaky Blinders (2014â€“ )',\n",
       " '58. House (2004â€“2012)',\n",
       " '59. Quantico (2015â€“2018)',\n",
       " '60. Orphan Black (2013â€“2017)',\n",
       " '61. Homeland (2011â€“2020)',\n",
       " '62. Blindspot (2015â€“2020)',\n",
       " \"63. DC's Legends of Tomorrow (2016â€“ )\",\n",
       " \"64. The Handmaid's Tale (2017â€“ )\",\n",
       " '65. Chilling Adventures of Sabrina (2018â€“2020)',\n",
       " '66. The Good Doctor (2017â€“ )',\n",
       " '67. Jane the Virgin (2014â€“2019)',\n",
       " '68. Glee (2009â€“2015)',\n",
       " '69. South Park (1997â€“ )',\n",
       " '70. Brooklyn Nine-Nine (2013â€“2021)',\n",
       " '71. Under the Dome (2013â€“2015)',\n",
       " '72. The Umbrella Academy (2019â€“ )',\n",
       " '73. True Detective (2014â€“2019)',\n",
       " '74. The OA (2016â€“2019)',\n",
       " '75. Desperate Housewives (2004â€“ )',\n",
       " '76. Better Call Saul (2015â€“2022)',\n",
       " '77. Bates Motel (2013â€“2017)',\n",
       " '78. The Punisher (2017â€“2019)',\n",
       " '79. Atypical (2017â€“2021)',\n",
       " '80. Dynasty (2017â€“ )',\n",
       " '81. This Is Us (2016â€“2022)',\n",
       " '82. The Good Place (2016â€“2020)',\n",
       " '83. Iron Fist (2017â€“2018)',\n",
       " '84. The Rain (2018â€“2020)',\n",
       " '85. Mindhunter (2017â€“2019)',\n",
       " '86. Revenge (2011â€“2015)',\n",
       " '87. Luke Cage (2016â€“2018)',\n",
       " '88. Scandal (2012â€“2018)',\n",
       " '89. The Defenders (2017)',\n",
       " '90. Big Little Lies (2017â€“2019)',\n",
       " '91. Insatiable (2018â€“2019)',\n",
       " '92. The Mentalist (2008â€“2015)',\n",
       " '93. The Crown (2016â€“ )',\n",
       " '94. Chernobyl (2019)',\n",
       " '95. iZombie (2015â€“2019)',\n",
       " '96. Reign (2013â€“2017)',\n",
       " '97. A Series of Unfortunate Events (2017â€“2019)',\n",
       " '98. Criminal Minds (2005â€“2020)',\n",
       " '99. Scream: The TV Series (2015â€“2019)',\n",
       " '100. The Haunting of Hill House (2018)']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = browser(\"//h3[@class ='lister-item-header']\")\n",
    "Name =[]\n",
    "for i in name:\n",
    "    Name.append(i.text)\n",
    "Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(2011â€“2019)',\n",
       " '(2016â€“ )',\n",
       " '(2010â€“2022)',\n",
       " '(2017â€“2020)',\n",
       " '(2014â€“2020)',\n",
       " '(2013â€“2019)',\n",
       " '(2017â€“ )',\n",
       " '(2005â€“ )',\n",
       " '(2014â€“ )',\n",
       " '(2012â€“2020)',\n",
       " '(2017â€“2021)',\n",
       " '(2007â€“2019)',\n",
       " '(2011â€“ )',\n",
       " '(2010â€“2017)',\n",
       " '(2013â€“2020)',\n",
       " '(2010â€“2017)',\n",
       " '(2009â€“2017)',\n",
       " '(2011â€“ )',\n",
       " '(2008â€“2013)',\n",
       " '(2016â€“2021)',\n",
       " '(2005â€“2020)',\n",
       " '(2005â€“2017)',\n",
       " '(2014â€“2020)',\n",
       " '(2011â€“2017)',\n",
       " '(1989â€“ )',\n",
       " '(2011â€“2018)',\n",
       " '(2015â€“2017)',\n",
       " '(2015â€“2018)',\n",
       " '(1994â€“2004)',\n",
       " '(2005â€“2014)',\n",
       " '(2011â€“2019)',\n",
       " '(2015â€“2019)',\n",
       " '(2013â€“2018)',\n",
       " '(2015â€“2021)',\n",
       " '(2007â€“2012)',\n",
       " '(2015â€“2018)',\n",
       " '(2014â€“2019)',\n",
       " '(2016â€“ )',\n",
       " '(2015â€“2019)',\n",
       " '(2009â€“2020)',\n",
       " '(2013â€“ )',\n",
       " '(2016â€“2019)',\n",
       " '(2017â€“2019)',\n",
       " '(2013â€“2018)',\n",
       " '(2017â€“2020)',\n",
       " '(2018â€“ )',\n",
       " '(2019â€“ )',\n",
       " '(2011â€“2021)',\n",
       " '(2011â€“2018)',\n",
       " '(2013â€“2020)',\n",
       " '(2018â€“ )',\n",
       " '(2006â€“2013)',\n",
       " '(2015â€“ )',\n",
       " '(1999â€“ )',\n",
       " '(2013â€“ )',\n",
       " '(2004â€“2010)',\n",
       " '(2014â€“ )',\n",
       " '(2004â€“2012)',\n",
       " '(2015â€“2018)',\n",
       " '(2013â€“2017)',\n",
       " '(2011â€“2020)',\n",
       " '(2015â€“2020)',\n",
       " '(2016â€“ )',\n",
       " '(2017â€“ )',\n",
       " '(2018â€“2020)',\n",
       " '(2017â€“ )',\n",
       " '(2014â€“2019)',\n",
       " '(2009â€“2015)',\n",
       " '(1997â€“ )',\n",
       " '(2013â€“2021)',\n",
       " '(2013â€“2015)',\n",
       " '(2019â€“ )',\n",
       " '(2014â€“2019)',\n",
       " '(2016â€“2019)',\n",
       " '(2004â€“ )',\n",
       " '(2015â€“2022)',\n",
       " '(2013â€“2017)',\n",
       " '(2017â€“2019)',\n",
       " '(2017â€“2021)',\n",
       " '(2017â€“ )',\n",
       " '(2016â€“2022)',\n",
       " '(2016â€“2020)',\n",
       " '(2017â€“2018)',\n",
       " '(2018â€“2020)',\n",
       " '(2017â€“2019)',\n",
       " '(2011â€“2015)',\n",
       " '(2016â€“2018)',\n",
       " '(2012â€“2018)',\n",
       " '(2017)',\n",
       " '(2017â€“2019)',\n",
       " '(2018â€“2019)',\n",
       " '(2008â€“2015)',\n",
       " '(2016â€“ )',\n",
       " '(2019)',\n",
       " '(2015â€“2019)',\n",
       " '(2013â€“2017)',\n",
       " '(2017â€“2019)',\n",
       " '(2005â€“2020)',\n",
       " '(2015â€“2019)',\n",
       " '(2018)']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year = browser(\"//span[@class ='lister-item-year text-muted unbold']\")\n",
    "Year =[]\n",
    "for i in year:\n",
    "    Year.append(i.text)\n",
    "Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Action, Adventure, Drama',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Drama, Horror, Thriller',\n",
       " 'Drama, Mystery, Thriller',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Comedy, Crime, Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Romance',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Action, Adventure, Crime',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Romance',\n",
       " 'Drama, Sci-Fi, Thriller',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Drama, Mystery, Romance',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Drama, Horror, Thriller',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Crime, Drama, Fantasy',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Action, Crime, Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Action, Drama, Fantasy',\n",
       " 'Animation, Comedy',\n",
       " 'Adventure, Fantasy, Romance',\n",
       " 'Biography, Crime, Drama',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Romance',\n",
       " 'Comedy, Romance',\n",
       " 'Comedy, Drama',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Drama, Romance',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Action, Crime, Drama',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Drama, Romance',\n",
       " 'Animation, Adventure, Comedy',\n",
       " 'Action, Drama, Fantasy',\n",
       " 'Adventure, Comedy, Crime',\n",
       " 'Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Comedy, Drama',\n",
       " 'Comedy, Drama',\n",
       " 'Comedy',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Crime, Drama, Romance',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Horror, Sci-Fi',\n",
       " 'Animation, Comedy',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Adventure, Drama, Fantasy',\n",
       " 'Crime, Drama',\n",
       " 'Drama, Mystery',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Action, Drama, Sci-Fi',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Action, Crime, Drama',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Drama, Sci-Fi, Thriller',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Drama',\n",
       " 'Comedy',\n",
       " 'Comedy, Drama, Music',\n",
       " 'Animation, Comedy',\n",
       " 'Comedy, Crime',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Action, Adventure, Comedy',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Fantasy, Mystery',\n",
       " 'Comedy, Drama, Mystery',\n",
       " 'Crime, Drama',\n",
       " 'Drama, Horror, Mystery',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Drama',\n",
       " 'Drama',\n",
       " 'Comedy, Drama, Romance',\n",
       " 'Comedy, Drama, Fantasy',\n",
       " 'Action, Adventure, Crime',\n",
       " 'Drama, Sci-Fi, Thriller',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Drama, Mystery, Thriller',\n",
       " 'Action, Crime, Drama',\n",
       " 'Drama, Thriller',\n",
       " 'Action, Adventure, Crime',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Comedy, Drama, Thriller',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Biography, Drama, History',\n",
       " 'Drama, History, Thriller',\n",
       " 'Comedy, Crime, Drama',\n",
       " 'Drama, Fantasy',\n",
       " 'Adventure, Comedy, Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Comedy, Crime, Drama',\n",
       " 'Drama, Horror, Mystery']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre = browser(\"//span[@class ='genre']\")\n",
    "Genre =[]\n",
    "for i in genre:\n",
    "    Genre.append(i.text)\n",
    "Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['57 min',\n",
       " '51 min',\n",
       " '44 min',\n",
       " '60 min',\n",
       " '43 min',\n",
       " '59 min',\n",
       " '45 min',\n",
       " '41 min',\n",
       " '43 min',\n",
       " '42 min',\n",
       " '70 min',\n",
       " '22 min',\n",
       " '60 min',\n",
       " '88 min',\n",
       " '44 min',\n",
       " '44 min',\n",
       " '43 min',\n",
       " '60 min',\n",
       " '49 min',\n",
       " '42 min',\n",
       " '44 min',\n",
       " '44 min',\n",
       " '43 min',\n",
       " '41 min',\n",
       " '22 min',\n",
       " '60 min',\n",
       " '49 min',\n",
       " '54 min',\n",
       " '22 min',\n",
       " '22 min',\n",
       " '44 min',\n",
       " '49 min',\n",
       " '45 min',\n",
       " '43 min',\n",
       " '42 min',\n",
       " '60 min',\n",
       " '42 min',\n",
       " '62 min',\n",
       " '56 min',\n",
       " '22 min',\n",
       " '23 min',\n",
       " '42 min',\n",
       " '25 min',\n",
       " '51 min',\n",
       " '60 min',\n",
       " '60 min',\n",
       " '45 min',\n",
       " '46 min',\n",
       " '22 min',\n",
       " '45 min',\n",
       " '45 min',\n",
       " '53 min',\n",
       " '44 min',\n",
       " '22 min',\n",
       " '43 min',\n",
       " '44 min',\n",
       " '60 min',\n",
       " '44 min',\n",
       " '42 min',\n",
       " '44 min',\n",
       " '55 min',\n",
       " '42 min',\n",
       " '42 min',\n",
       " '60 min',\n",
       " '60 min',\n",
       " '41 min',\n",
       " '60 min',\n",
       " '44 min',\n",
       " '22 min',\n",
       " '22 min',\n",
       " '43 min',\n",
       " '60 min',\n",
       " '55 min',\n",
       " '60 min',\n",
       " '45 min',\n",
       " '46 min',\n",
       " '45 min',\n",
       " '53 min',\n",
       " '30 min',\n",
       " '42 min',\n",
       " '45 min',\n",
       " '22 min',\n",
       " '55 min',\n",
       " '45 min',\n",
       " '60 min',\n",
       " '44 min',\n",
       " '55 min',\n",
       " '43 min',\n",
       " '50 min',\n",
       " '60 min',\n",
       " '45 min',\n",
       " '43 min',\n",
       " '58 min',\n",
       " '330 min',\n",
       " '42 min',\n",
       " '42 min',\n",
       " '50 min',\n",
       " '42 min',\n",
       " '45 min',\n",
       " '572 min']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runtime = browser(\"//span[@class ='runtime']\")\n",
    "Runtime = []\n",
    "for i in runtime:\n",
    "    Runtime.append(i.text)\n",
    "Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9.2',\n",
       " '8.7',\n",
       " '8.2',\n",
       " '7.5',\n",
       " '7.6',\n",
       " '8',\n",
       " '6.7',\n",
       " '7.5',\n",
       " '7.6',\n",
       " '7.5',\n",
       " '8.2',\n",
       " '8.1',\n",
       " '8.8',\n",
       " '9.1',\n",
       " '8.5',\n",
       " '7.4',\n",
       " '7.7',\n",
       " '8',\n",
       " '9.4',\n",
       " '8.1',\n",
       " '8.4',\n",
       " '8.3',\n",
       " '8.1',\n",
       " '7.6',\n",
       " '8.6',\n",
       " '7.7',\n",
       " '8.8',\n",
       " '8.6',\n",
       " '8.8',\n",
       " '8.3',\n",
       " '8.4',\n",
       " '8.5',\n",
       " '8.2',\n",
       " '6.2',\n",
       " '7.4',\n",
       " '8.3',\n",
       " '7.8',\n",
       " '8.6',\n",
       " '7.9',\n",
       " '8.4',\n",
       " '9.2',\n",
       " '6.6',\n",
       " '8.1',\n",
       " '8.7',\n",
       " '8.8',\n",
       " '7.5',\n",
       " '8.3',\n",
       " '8.5',\n",
       " '7.7',\n",
       " '7.5',\n",
       " '7.7',\n",
       " '8.6',\n",
       " '6.9',\n",
       " '8.1',\n",
       " '8',\n",
       " '8.3',\n",
       " '8.8',\n",
       " '8.7',\n",
       " '6.7',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '7.4',\n",
       " '6.8',\n",
       " '8.4',\n",
       " '7.5',\n",
       " '8.1',\n",
       " '7.8',\n",
       " '6.7',\n",
       " '8.7',\n",
       " '8.4',\n",
       " '6.6',\n",
       " '8',\n",
       " '8.9',\n",
       " '7.8',\n",
       " '7.5',\n",
       " '8.8',\n",
       " '8.1',\n",
       " '8.5',\n",
       " '8.3',\n",
       " '7.3',\n",
       " '8.6',\n",
       " '8.2',\n",
       " '6.4',\n",
       " '6.3',\n",
       " '8.6',\n",
       " '7.8',\n",
       " '7.3',\n",
       " '7.7',\n",
       " '7.3',\n",
       " '8.5',\n",
       " '6.5',\n",
       " '8.1',\n",
       " '8.6',\n",
       " '9.4',\n",
       " '7.8',\n",
       " '7.5',\n",
       " '7.8',\n",
       " '8.1',\n",
       " '7.1',\n",
       " '8.6']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = browser(\"//div[@class ='ipl-rating-star small']\")\n",
    "Rating = []\n",
    "for i in ratings:\n",
    "    Rating.append(i.text)\n",
    "Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1,883,467',\n",
       " '916,741',\n",
       " '905,003',\n",
       " '271,047',\n",
       " '231,410',\n",
       " '287,456',\n",
       " '130,245',\n",
       " '274,315',\n",
       " '325,349',\n",
       " '418,002',\n",
       " '391,498',\n",
       " '753,076',\n",
       " '481,154',\n",
       " '852,764',\n",
       " '472,032',\n",
       " '157,824',\n",
       " '298,108',\n",
       " '295,484',\n",
       " '1,590,840',\n",
       " '287,568',\n",
       " '410,742',\n",
       " '499,410',\n",
       " '139,240',\n",
       " '135,978',\n",
       " '381,269',\n",
       " '214,739',\n",
       " '382,977',\n",
       " '381,600',\n",
       " '902,635',\n",
       " '634,339',\n",
       " '380,071',\n",
       " '353,575',\n",
       " '125,019',\n",
       " '117,455',\n",
       " '162,404',\n",
       " '146,001',\n",
       " '218,783',\n",
       " '452,653',\n",
       " '200,726',\n",
       " '387,411',\n",
       " '436,004',\n",
       " '57,500',\n",
       " '163,605',\n",
       " '481,483',\n",
       " '324,361',\n",
       " '63,551',\n",
       " '216,836',\n",
       " '216,948',\n",
       " '204,733',\n",
       " '207,544',\n",
       " '168,024',\n",
       " '677,659',\n",
       " '120,170',\n",
       " '316,454',\n",
       " '218,944',\n",
       " '519,887',\n",
       " '414,448',\n",
       " '431,849',\n",
       " '58,862',\n",
       " '105,781',\n",
       " '325,947',\n",
       " '69,757',\n",
       " '97,826',\n",
       " '204,027',\n",
       " '84,685',\n",
       " '78,217',\n",
       " '43,380',\n",
       " '141,641',\n",
       " '344,842',\n",
       " '266,109',\n",
       " '103,535',\n",
       " '182,373',\n",
       " '523,782',\n",
       " '96,821',\n",
       " '121,563',\n",
       " '359,002',\n",
       " '101,977',\n",
       " '200,369',\n",
       " '77,012',\n",
       " '17,513',\n",
       " '119,028',\n",
       " '132,831',\n",
       " '120,955',\n",
       " '33,738',\n",
       " '244,033',\n",
       " '116,113',\n",
       " '121,883',\n",
       " '69,766',\n",
       " '96,415',\n",
       " '174,128',\n",
       " '25,074',\n",
       " '172,481',\n",
       " '175,714',\n",
       " '615,796',\n",
       " '63,410',\n",
       " '45,925',\n",
       " '56,793',\n",
       " '177,502',\n",
       " '36,933',\n",
       " '204,284']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "votes = browser(\"//span[@name ='nv']\")\n",
    "Vote = []\n",
    "for i in votes:\n",
    "    Vote.append(i.text)\n",
    "Vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Vote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year_Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run Time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. Game of Thrones (2011â€“2019)</td>\n",
       "      <td>(2011â€“2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1,883,467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2. Stranger Things (2016â€“ )</td>\n",
       "      <td>(2016â€“ )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>916,741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3. The Walking Dead (2010â€“2022)</td>\n",
       "      <td>(2010â€“2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.2</td>\n",
       "      <td>905,003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4. 13 Reasons Why (2017â€“2020)</td>\n",
       "      <td>(2017â€“2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>271,047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5. The 100 (2014â€“2020)</td>\n",
       "      <td>(2014â€“2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>231,410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96. Reign (2013â€“2017)</td>\n",
       "      <td>(2013â€“2017)</td>\n",
       "      <td>Drama, Fantasy</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>45,925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97. A Series of Unfortunate Events (2017â€“2019)</td>\n",
       "      <td>(2017â€“2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>56,793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98. Criminal Minds (2005â€“2020)</td>\n",
       "      <td>(2005â€“2020)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>177,502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99. Scream: The TV Series (2015â€“2019)</td>\n",
       "      <td>(2015â€“2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>36,933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100. The Haunting of Hill House (2018)</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>204,284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Name    Year_Span  \\\n",
       "0                   1. Game of Thrones (2011â€“2019)  (2011â€“2019)   \n",
       "1                      2. Stranger Things (2016â€“ )     (2016â€“ )   \n",
       "2                  3. The Walking Dead (2010â€“2022)  (2010â€“2022)   \n",
       "3                    4. 13 Reasons Why (2017â€“2020)  (2017â€“2020)   \n",
       "4                           5. The 100 (2014â€“2020)  (2014â€“2020)   \n",
       "..                                             ...          ...   \n",
       "95                           96. Reign (2013â€“2017)  (2013â€“2017)   \n",
       "96  97. A Series of Unfortunate Events (2017â€“2019)  (2017â€“2019)   \n",
       "97                  98. Criminal Minds (2005â€“2020)  (2005â€“2020)   \n",
       "98           99. Scream: The TV Series (2015â€“2019)  (2015â€“2019)   \n",
       "99          100. The Haunting of Hill House (2018)       (2018)   \n",
       "\n",
       "                       Genre Run Time Ratings      Votes  \n",
       "0   Action, Adventure, Drama   57 min     9.2  1,883,467  \n",
       "1     Drama, Fantasy, Horror   51 min     8.7    916,741  \n",
       "2    Drama, Horror, Thriller   44 min     8.2    905,003  \n",
       "3   Drama, Mystery, Thriller   60 min     7.5    271,047  \n",
       "4     Drama, Mystery, Sci-Fi   43 min     7.6    231,410  \n",
       "..                       ...      ...     ...        ...  \n",
       "95            Drama, Fantasy   42 min     7.5     45,925  \n",
       "96  Adventure, Comedy, Drama   50 min     7.8     56,793  \n",
       "97     Crime, Drama, Mystery   42 min     8.1    177,502  \n",
       "98      Comedy, Crime, Drama   45 min     7.1     36,933  \n",
       "99    Drama, Horror, Mystery  572 min     8.6    204,284  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb = pd.DataFrame({})\n",
    "imdb['Name'] = Name\n",
    "imdb['Year_Span'] = Year\n",
    "imdb['Genre'] = Genre\n",
    "imdb['Run Time'] = Runtime\n",
    "imdb['Ratings'] = Rating\n",
    "imdb['Votes'] = Vote\n",
    "imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Details of Datasets from UCI machine learning repositories.Url = https://archive.ics.uci.edu/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = (\"https://archive.ics.uci.edu/\")\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
